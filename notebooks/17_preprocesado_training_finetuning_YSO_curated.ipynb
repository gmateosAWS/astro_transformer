{
 "cells": [
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "f6f4e81f",
   "metadata": {},
   "source": [
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "_M√°ster Universitario en Inteligencia Artificial_\n",
    "\n",
    "_Trabajo Fin de M√°ster_\n",
    "\n",
    "- Gustavo Mateos Santos\n",
    "- gustavo.mateos830@comunidadunir.net\n",
    "\n",
    "# Clasificaci√≥n autom√°tica de estrellas variables con modelos Transformer aplicados a series temporales\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62128cf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install missing packages\n",
    "%pip install torch lightkurve\n",
    "%pip install -q pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "455e0895-292c-4535-9e86-1e21e24e186d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.2.2\n",
      "Lightkurve: 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import torch, lightkurve as lk\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Lightkurve:\", lk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb5af2",
   "metadata": {},
   "source": [
    "## **Fase 2: Dise√±o e Implementaci√≥n del Modelo Transformer**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3655f64-8335-4f0c-bdba-6ad9506ded8b",
   "metadata": {},
   "source": [
    "\n",
    "## **NUEVO CICLO DE ENTRENAMIENTO+FINE-TUNING DESPUES DE REDUCIR A 7 CLASES (MEJOR MODELO HASTA AHORA) Y REFORZAR DATASET CON ERRORES DE CLASIFICACION (YSO)**\n",
    "\n",
    "√öltimo ciclo de pruebas: despu√©s de llegar al mejor modelo en `astro_transformer_fase2_sagemaker.ipynb`, se analizaron los errores de clasificaci√≥n del modelo y se vio que la clase YSO, aun siendo ahora la mayoritaria en el dataset, generaba muchos falsos positivos (clase predicha YSO pero otra clase real) y tambi√©n un buen n√∫mero de falsos negativos (otras clases que el modelo confund√≠a y predec√≠a como YSO). \n",
    "\n",
    "En el notebook `16_preprocesado_YSO_review.ipynb` se generaron los datasets con IDs de objeto, as√≠ como CSVs de errores de clasificaci√≥n, tambi√©n con IDs de objeto. Cruzando todo ello se concluy√≥:\n",
    "\n",
    "- üîç Total de FALSOS NEGATIVOS (YSO reales pero no predichas): **430**\n",
    "- üîç Total de FALSOS POSITIVOS (YSO predichas pero no reales): **858**\n",
    "- üîç Total de curvas a eliminar: 1288\n",
    "\n",
    "Motivo_descarte\n",
    "YSO predicha incorrectamente (FP)    858\n",
    "YSO mal clasificada (FN)             430\n",
    "\n",
    "üìä **Curvas confusas**. Desglose por clase original (impacto en dataset):\n",
    "\n",
    "| Clase                | N¬∫ curvas |\n",
    "| -------------------- | --------- |\n",
    "| Young Stellar Object | 430     |\n",
    "| Eclipsing Binary     | 238     |\n",
    "| Cataclysmic          | 195     |\n",
    "| Rotational           | 170     |\n",
    "| Delta Scuti          | 101     |\n",
    "| RR Lyrae             | 97     |\n",
    "| Irregular            | 57     |\n",
    "\n",
    "‚úÖ Guardado en: ../data/train/curvas_a_eliminar_por_confusion_yso.csv\n",
    "\n",
    "La idea es hacer un nuevo preprocesado + training + fine tuning, en el que los datasets se van a generar nuevos pero filtrando las clases de manera que se eliminen las curvas identificadas como dudosas o confusas: \n",
    "\n",
    "- üìÇ [INFO] IDs a excluir por filtrado: 1288\n",
    "- üìÇ [INFO] Exclusiones por clase: {'Cataclysmic': 195, 'Delta Scuti': 97, 'Eclipsing Binary': 238, 'Irregular': 57, 'RR Lyrae': 101, 'Rotational': 170, 'Young Stellar Object': 430}\n",
    "\n",
    "#### 1. **PREPROCESADO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f0b74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Cargando datos en lotes con PyArrow...\n",
      "üìÇ [INFO] IDs a excluir por filtrado: 1288\n",
      "üìÇ [INFO] Exclusiones por clase: {'Cataclysmic': 195, 'Delta Scuti': 97, 'Eclipsing Binary': 238, 'Irregular': 57, 'RR Lyrae': 101, 'Rotational': 170, 'Young Stellar Object': 430}\n",
      "üíæ [INFO] Cargando agrupaci√≥n de curvas desde cache: /home/ec2-user/SageMaker/astro_transformer/src/fase2/../../data/train/grouped_data.pkl\n",
      "‚úÖ [INFO] Agrupaci√≥n cargada desde cache. Total objetos: 54947\n",
      "‚è≥ [INFO] Tiempo en agrupaci√≥n de datos: 248.9 segundos\n",
      "üöÄ Procesando 54947 curvas en paralelo usando 20 CPUs...\n",
      "‚è≥ [INFO] Tiempo en procesamiento paralelo: 82.1 segundos\n",
      "üîã [INFO] Curvas v√°lidas tras filtrado: 54854\n",
      "üîé Ejemplos aleatorios despu√©s del filtrado final:\n",
      "ID: ASASSN-V J031510.38+545659.0, Clase: Rotational\n",
      "ID: ASASSN-V J051539.55-611420.1, Clase: Cataclysmic\n",
      "ID: ASASSN-V J025201.04-233827.4, Clase: Irregular\n",
      "ID: ASASSN-V J153259.00-332342.9, Clase: RR Lyrae\n",
      "ID: ASASSN-V J073526.05-305037.0, Clase: Delta Scuti\n",
      "\n",
      "üîç Realizando prueba r√°pida en caracter√≠sticas auxiliares...\n",
      "‚úÖ Sample 0 sin problemas: [ 1.28437917  1.55698524  0.76734698  0.45859354  1.38775498 -0.88182198\n",
      " -0.34117656]\n",
      "‚úÖ Sample 1 sin problemas: [-0.47815431 -0.39705882 -0.50448982 -0.24344532 -0.40000002 -0.28730509\n",
      " -0.06915612]\n",
      "‚úÖ Sample 2 sin problemas: [-0.34753579 -0.25       -0.27346939 -0.01872623 -0.23673468 -0.03655882\n",
      "  0.09026367]\n",
      "‚úÖ Sample 3 sin problemas: [-0.47576391 -0.36764708 -0.54040816 -0.56221386 -0.3755102  -0.05316845\n",
      " -0.34109143]\n",
      "‚úÖ Sample 4 sin problemas: [-0.52642557 -0.4485294  -0.56734693 -0.53474819 -0.46530612  0.10530449\n",
      "  0.09294471]\n",
      "‚úÖ Sample 5 sin problemas: [0.36030296 0.40073522 0.48571431 0.4935497  0.40000002 0.92382646\n",
      " 0.11676931]\n",
      "‚úÖ Sample 6 sin problemas: [-0.30398791 -0.12591914 -0.44571429 -1.00707417 -0.15918366  0.27427012\n",
      " -0.52701617]\n",
      "‚úÖ Sample 7 sin problemas: [-0.34231399 -0.2867647  -0.14367347 -0.13150229 -0.27755103 -1.55976746\n",
      "  3.6033599 ]\n",
      "‚úÖ Sample 8 sin problemas: [-0.42918715 -0.35661764 -0.4465306  -0.37328315 -0.35918367  0.19681652\n",
      " -0.07125449]\n",
      "‚úÖ Sample 9 sin problemas: [ 1.83107931  1.76378684  1.43020406  1.25052029  1.75510205 -1.25816176\n",
      "  0.04537703]\n",
      "‚úÖ Prueba r√°pida completada.\n",
      "üìÅ Features median y IQR guardados en: /home/ec2-user/SageMaker/astro_transformer/src/fase2/../../data/train/features_stats.pkl\n",
      "[INFO] Uso de memoria de sequences: 10462.57 MB\n",
      "[INFO] Uso de memoria de masks: 10462.57 MB\n",
      "[INFO] Uso de memoria de features: 2.93 MB\n",
      "[INFO] Uso de memoria de labels: 0.21 MB\n",
      "[INFO] N curvas: 54854, seq_length: 25000\n",
      "[INFO] Estimaci√≥n memoria sequences (float16): 2.55 GB\n",
      "[INFO] Estimaci√≥n memoria sequences (float32): 5.11 GB\n",
      "[INFO] Si tienes problemas de memoria, considera usar almacenamiento en disco y Dataset bajo demanda.\n",
      "üíæ [INFO] Guardando label_encoder.pkl...\n",
      "üìä Recuento por clase codificada:\n",
      " 4 (RR Lyrae): 9000\n",
      " 1 (Delta Scuti): 7279\n",
      " 5 (Rotational): 9000\n",
      " 6 (Young Stellar Object): 9548\n",
      " 2 (Eclipsing Binary): 9000\n",
      " 0 (Cataclysmic): 2027\n",
      " 3 (Irregular): 9000\n",
      "üìù [INFO] Realizando split train/val/test...\n",
      "Train: 38398 | Val: 10970 | Test: 5486\n",
      "üìä [INFO] IDs de refuerzo incluidos en train: 0\n",
      "üíæ [INFO] Guardando datasets serializados en formato .pt...\n",
      "\n",
      "üìâ Resumen de curvas descartadas:\n",
      "üî∏ Ok                            : 54854\n",
      "üî∏ Short curve                   : 93\n",
      "‚úÖ Datos preparados como secuencias normalizadas y m√°scaras.\n",
      "‚è≥ [INFO] Tiempo total de ejecuci√≥n: 8.28 minutos (496.7 segundos)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f526eab2b90>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f526eab3f10>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# A√±adir la ra√≠z del proyecto al path\n",
    "ROOT_DIR = Path.cwd().parent  # <- sube un nivel para alcanzar la ra√≠z del proyecto\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT_DIR))\n",
    "\n",
    "# Ignorar solo los RuntimeWarning de numpy (como overflows en reduce)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"numpy\")\n",
    "\n",
    "from src.fase2.script_1_transformer_preprocessing_optimizado_2 import main as preprocessing_optimized_YSO_cleaning\n",
    "\n",
    "# Balanceo de clases \n",
    "max_per_class_override={\n",
    "    \"Irregular\": 9000,\n",
    "    \"Rotational\": 9000,\n",
    "    \"Eclipsing Binary\": 9000,\n",
    "    \"Delta Scuti\": None,            # 7.550 ‚Üí TODAS\n",
    "    \"RR Lyrae\": 9000,               # 41.208 ‚Üí RECORTAMOS A 9.000\n",
    "    \"Young Stellar Object\": None,   # 9.809 ‚Üí TODAS \n",
    "    \"Cataclysmic\": None,            # 2.080 ‚Üí TODAS\n",
    "    \"White Dwarf\": 0,               # 0 ‚Üí LA ELIMINAMOS\n",
    "    \"Variable\": 0                   # 0 ‚Üí LA ELIMINAMOS\n",
    "}\n",
    "\n",
    "# El script se ha adaptado para filtrar curvas malas directamente con el parametro `filtrar_curvas_malas`\n",
    "preprocessing_optimized_YSO_cleaning(\n",
    "    seq_length=25000,\n",
    "    max_per_class=None, # usamos override completo\n",
    "    max_per_class_override=max_per_class_override,\n",
    "    parquet_batch_size=10_000_000,\n",
    "    dataloader_batch_size=128,\n",
    "    num_workers=20,\n",
    "    filtrar_curvas_malas=\"../data/train/curvas_a_eliminar_por_confusion_yso.csv\"\n",
    "    #errores_csv_path=Path(\"../outputs/errores_mal_clasificados.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388507aa",
   "metadata": {},
   "source": [
    "\n",
    "#### Nueva distribuci√≥n de clases tras preprocesado:\n",
    "\n",
    "\n",
    "| Cod. | Clase                | N¬∫ curvas |\n",
    "| ---- | -------------------- | --------- |\n",
    "| 0    | Cataclysmic          | **2.027**     |\n",
    "| 1    | Delta Scuti          | **7.279**     |\n",
    "| 2    | Eclipsing Binary     | **9.000**     |\n",
    "| 3    | Irregular            | **9.000**     |\n",
    "| 4    | RR Lyrae             | **9.000**     |\n",
    "| 5    | Rotational           | **9.000**     |\n",
    "| 6    | Young Stellar Object | **9.548**    |\n",
    "|      | TOTAL                | **54.854** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb13d5e-ca00-4cd1-b43a-ea01815d69dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N¬∫ de elementos devueltos por __getitem__: 5\n",
      "Elemento 0: <class 'torch.Tensor'>, shape o valor: torch.Size([25000])\n",
      "Elemento 1: <class 'torch.Tensor'>, shape o valor: torch.Size([])\n",
      "Elemento 2: <class 'torch.Tensor'>, shape o valor: torch.Size([25000])\n",
      "Elemento 3: <class 'torch.Tensor'>, shape o valor: torch.Size([7])\n",
      "Elemento 4: <class 'str'>, shape o valor: ASASSN-V J024446.27+065612.3\n",
      "Contenido del label encoder:\n",
      "Cataclysmic: 0\n",
      "Delta Scuti: 1\n",
      "Eclipsing Binary: 2\n",
      "Irregular: 3\n",
      "RR Lyrae: 4\n",
      "Rotational: 5\n",
      "Young Stellar Object: 6\n",
      "\n",
      "üîç Verificaci√≥n manual de los primeros errores:\n",
      "ID: ASASSN-V J024446.27+065612.3\n",
      " - Predicha: Young Stellar Object\n",
      " - Real (seg√∫n modelo): Young Stellar Object\n",
      " - Real (en CSV original): Young Stellar Object\n",
      "---\n",
      "ID: ASASSN-V J010244.04+562906.6\n",
      " - Predicha: Irregular\n",
      " - Real (seg√∫n modelo): Irregular\n",
      " - Real (en CSV original): Irregular\n",
      "---\n",
      "ID: ASASSN-V J040748.13+452112.9\n",
      " - Predicha: Eclipsing Binary\n",
      " - Real (seg√∫n modelo): Eclipsing Binary\n",
      " - Real (en CSV original): Eclipsing Binary\n",
      "---\n",
      "ID: ASASSN-V J040619.69+605630.5\n",
      " - Predicha: Young Stellar Object\n",
      " - Real (seg√∫n modelo): Young Stellar Object\n",
      " - Real (en CSV original): Young Stellar Object\n",
      "---\n",
      "ID: ASASSN-V J184238.18-414414.5\n",
      " - Predicha: Eclipsing Binary\n",
      " - Real (seg√∫n modelo): Eclipsing Binary\n",
      " - Real (en CSV original): Eclipsing Binary\n",
      "---\n",
      "YSOs mal clasificadas detectadas: 852\n",
      "Total de errores detectados: 2298\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.serialization\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# A√±adir la ra√≠z del proyecto al path\n",
    "ROOT_DIR = Path.cwd().parent  # <- sube un nivel para alcanzar la ra√≠z del proyecto\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT_DIR))\n",
    "\n",
    "# Ignorar solo los RuntimeWarning de numpy (como overflows en reduce)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"numpy\")\n",
    "\n",
    "from src.fase2.script_2_transformer_fine_tuning_optimizado import AstroConformerClassifier as AstroConformerClassifier, evaluate\n",
    "\n",
    "# Detectar dispositivo\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# acciones para resolver los problemas de memoria\n",
    "# 1. Liberar memoria\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 2. Optimizar fragmentacion\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def detectar_todos_los_errores(preds, true, ids, label_encoder):\n",
    "    \"\"\"\n",
    "    Retorna un DataFrame con todos los errores de clasificaci√≥n con clase real y predicha bien decodificadas.\n",
    "    \"\"\"\n",
    "    df_labels = pd.DataFrame({\n",
    "        \"id_objeto\": ids,\n",
    "        \"true_label\": true,\n",
    "        \"pred_label\": preds\n",
    "    })\n",
    "\n",
    "    # Decodificar nombres\n",
    "    label_decoder = {v: k for k, v in label_encoder.items()}\n",
    "    df_labels[\"clase_real\"] = df_labels[\"true_label\"].map(label_decoder)\n",
    "    df_labels[\"clase_predicha\"] = df_labels[\"pred_label\"].map(label_decoder)\n",
    "\n",
    "    # Filtrar errores\n",
    "    df_errores = df_labels[df_labels[\"clase_real\"] != df_labels[\"clase_predicha\"]][\n",
    "        [\"id_objeto\", \"clase_real\", \"clase_predicha\"]\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    return df_errores\n",
    "\n",
    "def detectar_yso_confundidas(preds, true, ids, label_encoder):\n",
    "    \"\"\"\n",
    "    Retorna un DataFrame con los objetos cuya clase fue predicha como YSO pero no lo eran.\n",
    "    \"\"\"\n",
    "    df_labels = pd.DataFrame({\n",
    "        \"id_objeto\": ids,\n",
    "        \"true_label\": true,\n",
    "        \"pred_label\": preds\n",
    "    })\n",
    "\n",
    "    label_decoder = {v: k for k, v in label_encoder.items()}\n",
    "    df_labels[\"clase_real\"] = df_labels[\"true_label\"].map(label_decoder)\n",
    "    df_labels[\"clase_predicha\"] = df_labels[\"pred_label\"].map(label_decoder)\n",
    "\n",
    "    df_yso_mal = df_labels[\n",
    "        (df_labels[\"clase_predicha\"] == \"Young Stellar Object\") &\n",
    "        (df_labels[\"clase_real\"] != \"Young Stellar Object\")\n",
    "    ][[\"id_objeto\", \"clase_real\", \"clase_predicha\"]].reset_index(drop=True)\n",
    "\n",
    "    return df_yso_mal\n",
    "\n",
    "\n",
    "# Cargar dataset y label encoder\n",
    "from src.fase2.script_1_transformer_preprocessing_optimizado_2 import LightCurveDataset\n",
    "#torch.serialization.add_safe_globals([LightCurveDataset])\n",
    "\n",
    "val_dataset = torch.load(\"../data/train/val_dataset.pt\", weights_only=False)\n",
    "\n",
    "# Verificacion rapida\n",
    "# Cargar un sample cualquiera\n",
    "sample = val_dataset[0]\n",
    "# Ver cu√°ntos elementos contiene\n",
    "print(\"N¬∫ de elementos devueltos por __getitem__:\", len(sample))\n",
    "# Inspeccionar los elementos\n",
    "for i, item in enumerate(sample):\n",
    "    print(f\"Elemento {i}: {type(item)}, shape o valor: {getattr(item, 'shape', item)}\")\n",
    "\n",
    "with open(\"../data/train/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "num_classes = len(label_encoder)\n",
    "class_names = list(label_encoder.keys())\n",
    "\n",
    "# Dataloader con batch peque√±o\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=6, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "# Crear el modelo con la arquitectura esperada\n",
    "args = argparse.Namespace(\n",
    "    input_dim=1,\n",
    "    in_channels=1,\n",
    "    encoder_dim=256,\n",
    "    hidden_dim=384,\n",
    "    output_dim=num_classes,\n",
    "    num_heads=8,\n",
    "    num_layers=8,\n",
    "    dropout=0.4, dropout_p=0.4,\n",
    "    stride=32,\n",
    "    kernel_size=3,\n",
    "    norm=\"postnorm\",\n",
    "    encoder=[\"mhsa_pro\", \"conv\", \"conv\"],\n",
    "    timeshift=False,\n",
    "    device=device\n",
    ")\n",
    "model = AstroConformerClassifier(args, num_classes=len(label_encoder), feature_dim=7)\n",
    "\n",
    "# Cargar los pesos entrenados\n",
    "state_dict = torch.load(\"../outputs/mejor_modelo_finetuned_optimizado2_features_segunda_vuelta.pt\", map_location=\"cpu\")\n",
    "# Elimina el prefijo \"_orig_mod.\" de las claves\n",
    "new_state_dict = {k.replace(\"_orig_mod.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "# Pasar a GPU si est√° disponible\n",
    "model = model.to(device)\n",
    "model.eval()  # Muy importante: modo evaluaci√≥n\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Evaluar con IDs\n",
    "val_loss, preds, true, ids = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "#####################################\n",
    "# Mostrar el label encoder para asegurar consistencia (opcional si ya lo hiciste)\n",
    "print(\"Contenido del label encoder:\")\n",
    "for key, value in label_encoder.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "# Mapear IDs a clases reales desde el CSV original\n",
    "df_debug = pd.read_csv(\"../data/train/debug_clases_codificadas.csv\")\n",
    "dict_clases_reales = dict(zip(df_debug[\"id\"].astype(str), df_debug[\"clase_variable\"]))\n",
    "print(\"\\nüîç Verificaci√≥n manual de los primeros errores:\")\n",
    "for i in range(5):\n",
    "    pred_label = class_names[preds[i]]\n",
    "    true_label = class_names[true[i]]\n",
    "    object_id = str(ids[i])\n",
    "\n",
    "    real_ref = dict_clases_reales.get(object_id, \"NO_ENCONTRADO\")\n",
    "\n",
    "    print(f\"ID: {object_id}\")\n",
    "    print(f\" - Predicha: {pred_label}\")\n",
    "    print(f\" - Real (seg√∫n modelo): {true_label}\")\n",
    "    print(f\" - Real (en CSV original): {real_ref}\")\n",
    "    print(\"---\")\n",
    "#####################################\n",
    "\n",
    "# Detectar YSO mal clasificadas\n",
    "df_yso_mal = detectar_yso_confundidas(preds, true, ids, label_encoder)\n",
    "df_yso_mal.to_csv(\"../outputs/yso_clase_predicha_error2.csv\", index=False)\n",
    "# Detectar todos los errores\n",
    "df_todos_errores = detectar_todos_los_errores(preds, true, ids, label_encoder)\n",
    "df_todos_errores.to_csv(\"../outputs/todos_los_errores2.csv\", index=False)\n",
    "\n",
    "print(f\"YSOs mal clasificadas detectadas: {len(df_yso_mal)}\")\n",
    "print(f\"Total de errores detectados: {len(df_todos_errores)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d904e3-d714-469b-a747-9d820bb885e9",
   "metadata": {},
   "source": [
    "**Verificaciones...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb674f5c-57d0-41ad-8bef-12e0fb9e832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento 0: tipo=<class 'torch.Tensor'>, valor/shape=torch.Size([25000])\n",
      "Elemento 1: tipo=<class 'torch.Tensor'>, valor/shape=torch.Size([])\n",
      "Elemento 2: tipo=<class 'torch.Tensor'>, valor/shape=torch.Size([25000])\n",
      "Elemento 3: tipo=<class 'torch.Tensor'>, valor/shape=torch.Size([7])\n",
      "Elemento 4: tipo=<class 'str'>, valor/shape=ASASSN-V J062458.42-352355.1\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo para comprobar el contenido de un dataset .pt\n",
    "import torch\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# A√±adir la ra√≠z del proyecto al path\n",
    "ROOT_DIR = Path.cwd().parent  # <- sube un nivel para alcanzar la ra√≠z del proyecto\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT_DIR))\n",
    "    \n",
    "# Cargar el dataset (ajusta la ruta si es necesario)\n",
    "dataset = torch.load(\"../data/train/train_dataset.pt\", weights_only=False)\n",
    "\n",
    "# Obtener el primer elemento\n",
    "sample = dataset[0]\n",
    "\n",
    "# Mostrar informaci√≥n de cada campo\n",
    "for i, value in enumerate(sample):\n",
    "    print(f\"Elemento {i}: tipo={type(value)}, valor/shape={getattr(value, 'shape', value)}\")\n",
    "\n",
    "# Ejemplo de salida esperada:\n",
    "# Elemento 0: tipo=<class 'torch.Tensor'>, valor/shape=torch.Size([25000])\n",
    "# Elemento 1: tipo=<class 'torch.Tensor'>, valor/shape=tensor(3)\n",
    "# Elemento 2: tipo=<class 'torch.Tensor'>, valor/shape=torch.Size([25000])\n",
    "# Elemento 3: tipo=<class 'torch.Tensor'>, valor/shape=torch.Size([7])\n",
    "# Elemento 4: tipo=<class 'str'>, valor/shape=ASASSN-V J055358.70+014409.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9016a8f-b98e-47ce-b373-48c4acf7085e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Total errores analizados: 2298 (de 2298 totales)\n",
      "‚ùå Discrepancias reales: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar ambos archivos\n",
    "df_errores = pd.read_csv(\"../outputs/todos_los_errores2.csv\")\n",
    "df_ref = pd.read_csv(\"../data/train/debug_clases_codificadas.csv\")\n",
    "\n",
    "# Renombrar para evitar conflictos\n",
    "df_ref = df_ref.rename(columns={\"id\": \"id_objeto\", \"clase_variable\": \"clase_real_ref\"})\n",
    "\n",
    "# ‚ö†Ô∏è Filtrar solo errores cuyos IDs a√∫n est√°n en el dataset final\n",
    "df_errores_filtrados = df_errores[df_errores[\"id_objeto\"].isin(df_ref[\"id_objeto\"])].copy()\n",
    "\n",
    "# Cruzar por ID\n",
    "df_merge = pd.merge(df_errores_filtrados, df_ref, on=\"id_objeto\", how=\"left\")\n",
    "\n",
    "# Verificar discrepancias REALES\n",
    "df_discrepancias = df_merge[df_merge[\"clase_real\"] != df_merge[\"clase_real_ref\"]]\n",
    "\n",
    "# Mostrar resumen\n",
    "print(f\"üîé Total errores analizados: {len(df_errores_filtrados)} (de {len(df_errores)} totales)\")\n",
    "print(f\"‚ùå Discrepancias reales: {len(df_discrepancias)}\")\n",
    "if not df_discrepancias.empty:\n",
    "    print(df_discrepancias.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bd4f849-118e-4243-bf63-05bb07459c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verificaci√≥n directa en dataset:\n",
      "üßæ ID: ASASSN-V J032732.09+000351.4\n",
      " - Clase val_dataset: Eclipsing Binary\n",
      " - Clase CSV codificado: Eclipsing Binary (2)\n",
      "---\n",
      "üßæ ID: AP43491782\n",
      " - Clase val_dataset: Rotational\n",
      " - Clase CSV codificado: Rotational (5)\n",
      "---\n",
      "üßæ ID: ASASSN-V J051539.55-611420.1\n",
      " - Clase val_dataset: Cataclysmic\n",
      " - Clase CSV codificado: Cataclysmic (0)\n",
      "---\n",
      "üßæ ID: ASASSN-V J030537.58-593637.3\n",
      " - Clase val_dataset: Delta Scuti\n",
      " - Clase CSV codificado: Delta Scuti (1)\n",
      "---\n",
      "üßæ ID: ASASSN-V J002142.23-414002.5\n",
      " - Clase val_dataset: Delta Scuti\n",
      " - Clase CSV codificado: Delta Scuti (1)\n",
      "---\n",
      "üßæ ID: ASASSN-V J153259.00-332342.9\n",
      " - Clase val_dataset: RR Lyrae\n",
      " - Clase CSV codificado: RR Lyrae (4)\n",
      "---\n",
      "üßæ ID: ASASSN-V J031510.38+545659.0\n",
      " - Clase val_dataset: Rotational\n",
      " - Clase CSV codificado: Rotational (5)\n",
      "---\n",
      "üßæ ID: ASASSN-V J112416.67-110645.0\n",
      " - Clase val_dataset: RR Lyrae\n",
      " - Clase CSV codificado: RR Lyrae (4)\n",
      "---\n",
      "üßæ ID: ASASSN-V J114016.78+184126.4\n",
      " - Clase val_dataset: Delta Scuti\n",
      " - Clase CSV codificado: Delta Scuti (1)\n",
      "---\n",
      "üßæ ID: ASASSN-V J024305.65-065501.3\n",
      " - Clase val_dataset: Rotational\n",
      " - Clase CSV codificado: Rotational (5)\n",
      "---\n",
      "üßæ ID: ASASSN-V J025201.04-233827.4\n",
      " - Clase val_dataset: Irregular\n",
      " - Clase CSV codificado: Irregular (3)\n",
      "---\n",
      "üßæ ID: ASASSN-V J093207.60-823329.8\n",
      " - Clase val_dataset: Rotational\n",
      " - Clase CSV codificado: Rotational (5)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Cargar dataset\n",
    "val_dataset = torch.load(\"../data/train/val_dataset.pt\", weights_only=False)\n",
    "\n",
    "# Elegir IDs concretos con discrepancias\n",
    "ids_problema = [\n",
    "    \"ASASSN-V J024305.65-065501.3\",\n",
    "    \"ASASSN-V J031438.40+581303.1\",\n",
    "    \"ASASSN-V J093207.60-823329.8\",\n",
    "    \"ASASSN-V J114016.78+184126.4\",\n",
    "    \"459672\",\n",
    "    \"ASASSN-V J002142.23-414002.5\",\n",
    "    \"ASASSN-V J112416.67-110645.0\",\n",
    "    \"ASASSN-V J032732.09+000351.4\",\n",
    "    \"ASASSN-V J030537.58-593637.3\",\n",
    "    \"AP43491782\",\n",
    "    \"ASASSN-V J031510.38+545659.0\",  # Clase: Rotational\n",
    "    \"ASASSN-V J051539.55-611420.1\",  # Clase: Cataclysmic\n",
    "    \"ASASSN-V J025201.04-233827.4\",  # Clase: Irregular\n",
    "    \"ASASSN-V J153259.00-332342.9\",  # Clase: RR Lyrae\n",
    "    \"ASASSN-V J073526.05-305037.0\"   # Clase: Delta Scuti\n",
    "]\n",
    "# Cargar CSV codificado\n",
    "df_codificadas = pd.read_csv(\"../data/train/debug_clases_codificadas.csv\")\n",
    "df_codificadas = df_codificadas.set_index(\"id\")\n",
    "\n",
    "# Cargar encoder\n",
    "import pickle\n",
    "with open(\"../data/train/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "inv_label_encoder = {v: k for k, v in label_encoder.items()}\n",
    "\n",
    "# Buscar en val_dataset los objetos y verificar su label real\n",
    "print(\"üîç Verificaci√≥n directa en dataset:\")\n",
    "for i in range(len(val_dataset)):\n",
    "    _, label, _, _, id_obj = val_dataset[i]\n",
    "    if id_obj in ids_problema:\n",
    "        clase_real_dataset = inv_label_encoder[label.item()]\n",
    "        clase_codificada_csv = df_codificadas.loc[id_obj, \"clase_codificada\"]\n",
    "        clase_nombre_csv = df_codificadas.loc[id_obj, \"clase_variable\"]\n",
    "        print(f\"üßæ ID: {id_obj}\")\n",
    "        print(f\" - Clase val_dataset: {clase_real_dataset}\")\n",
    "        print(f\" - Clase CSV codificado: {clase_nombre_csv} ({clase_codificada_csv})\")\n",
    "        print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fce0260-668c-4621-8249-9ba2528ef09d",
   "metadata": {},
   "source": [
    "#### 2. **ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55010862-daa0-433f-a182-f8f02713698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# 2. Optimizar fragmentacion\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# A√±adir la ra√≠z del proyecto al path\n",
    "ROOT_DIR = Path.cwd().parent  # <- sube un nivel para alcanzar la ra√≠z del proyecto\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT_DIR))\n",
    "from src.fase2.script_2_transformer_training_optimizado2 import main as train_model_optimized2\n",
    "\n",
    "# Detectar dispositivo\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"üîÑ Restaurando datasets...\")\n",
    "start = time.time()\n",
    "train_dataset = torch.load(\"../data/train/train_dataset.pt\")\n",
    "val_dataset = torch.load(\"../data/train/val_dataset.pt\")\n",
    "print(f\"‚úÖ Dataset cargado en {time.time() - start:.2f} segundos\")\n",
    "\n",
    "# Cargar datasets completos\n",
    "print(\"üîÑ Cargando datasets completos...\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=192, shuffle=True, num_workers=10, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=192, shuffle=False, num_workers=10, pin_memory=True)\n",
    "\n",
    "print(f\"Total batches in train_loader: {len(train_loader)}\")\n",
    "print(f\"Total batches in val_loader: {len(val_loader)}\")\n",
    "\n",
    "######################################################################\n",
    "# Crear un mini-dataloader con batch peque√±o para inspecci√≥n\n",
    "batch_size = 256\n",
    "debug_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "for i, (x, y, mask, features, ids) in enumerate(debug_loader):\n",
    "    if i >= 100:\n",
    "        break\n",
    "    # Validaciones de tipo\n",
    "    if not torch.is_tensor(x) or not torch.is_tensor(mask):\n",
    "        print(f\"‚ùå No tensor en entrada en batch {i}\")\n",
    "    if not torch.is_tensor(y) or not torch.is_tensor(features):\n",
    "        print(f\"‚ùå y o features no son tensores en batch {i}\")\n",
    "    # Validaciones de contenido\n",
    "    if not torch.isfinite(x).all():\n",
    "        print(f\"‚ö†Ô∏è x contiene NaN o Inf en batch {i}\")\n",
    "    if not torch.isfinite(mask).all():\n",
    "        print(f\"‚ö†Ô∏è mask contiene NaN o Inf en batch {i}\")\n",
    "    if not torch.isfinite(features).all():\n",
    "        print(f\"‚ö†Ô∏è features contiene NaN o Inf en batch {i}:\\n{features}\")\n",
    "    # Validaci√≥n de forma\n",
    "    if features.shape[1] != 7:\n",
    "        print(f\"‚ùå Tama√±o inesperado en features en batch {i}: {features.shape}\")\n",
    "    if x.shape != mask.shape:\n",
    "        print(f\"‚ùå Tama√±os incompatibles en batch {i}: x {x.shape}, mask {mask.shape}\")\n",
    "    # Validaci√≥n de etiquetas\n",
    "    for j, label in enumerate(y):\n",
    "        if not isinstance(label.item(), int):\n",
    "            print(f\"‚ùå Etiqueta no entera en batch {i}, elemento {j}: {label}\")\n",
    "        if label.item() < 0 or label.item() >= 9:\n",
    "            print(f\"‚ùå Etiqueta fuera de rango en batch {i}, elemento {j}: {label.item()}\")\n",
    "print(\"‚úÖ Comprobaci√≥n completada\")\n",
    "######################################################################\n",
    "\n",
    "# Calcular n√∫mero de clases\n",
    "label_encoder = pickle.load(open(\"../data/train/label_encoder.pkl\", \"rb\"))\n",
    "num_classes = len(label_encoder)\n",
    "print(f\"TOTAL CLASES: {num_classes}\")\n",
    "\n",
    "# Ejecutar entrenamiento optimizado: \n",
    "# Ponderaci√≥n por clase con class_weight\n",
    "# dropout=0.3\n",
    "# Scheduler ReduceLROnPlateau\n",
    "# Early stopping\n",
    "# Curvas de p√©rdida y accuracy\n",
    "print(\"üöÄ Entrenando modelo optimizado...\")\n",
    "model = train_model_optimized2(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    label_encoder=label_encoder,\n",
    "    device=device,\n",
    "    epochs=50,\n",
    "    lr=3e-5,\n",
    "    freeze_encoder=True,  # transfer learning cl√°sico\n",
    "    patience=6,           # early stopping\n",
    "    debug=False           # True para depuraci√≥n\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c137eee",
   "metadata": {},
   "source": [
    "#### 3. **FINE TUNING 1/2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19603fd6-1c79-4be0-bd77-17a99678b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import os\n",
    "import torch, gc\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# A√±adir la ra√≠z del proyecto al path\n",
    "ROOT_DIR = Path.cwd().parent  # <- sube un nivel para alcanzar la ra√≠z del proyecto\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT_DIR))\n",
    "from src.fase2.script_2_transformer_fine_tuning_optimizado import main as fine_tuned_optimized_model\n",
    "\n",
    "# Detectar dispositivo\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# acciones para resolver los problemas de memoria\n",
    "# 1. Liberar memoria\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 2. Optimizar fragmentacion\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(\"üîÑ Restaurando datasets...\")\n",
    "train_dataset = torch.load(\"../data/train/train_dataset.pt\")\n",
    "val_dataset = torch.load(\"../data/train/val_dataset.pt\")\n",
    "\n",
    "# Cargar datasets completos\n",
    "print(\"üîÑ Cargando datasets completos...\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=12, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=12, pin_memory=True)\n",
    "\n",
    "print(f\"Total batches in train_loader: {len(train_loader)}\")\n",
    "print(f\"Total batches in val_loader: {len(val_loader)}\")\n",
    "\n",
    "label_encoder = pickle.load(open(\"../data/train/label_encoder.pkl\", \"rb\"))\n",
    "num_classes = len(label_encoder)\n",
    "print(f\"NUM CLASES: {num_classes}\")\n",
    "\n",
    "# Fine-tuning optimizado\n",
    "# Carga desde mejor_modelo_optimizado.pt\n",
    "# Doble learning rate (encoder / head)\n",
    "# Descongelado tras las primeras n epocas (freeze_epochs=n) o desde el principio (con freeze_encoder=False)\n",
    "# label_smoothing=0.1 para mejorar la generalizaci√≥n (lo hemos quitado en esta prueba)\n",
    "# Optimizaci√≥n por AdamW con weight_decay.\n",
    "print(\"üöÄ Fine-tuning sobre mejor modelo optimizado...\")\n",
    "model = fine_tuned_optimized_model(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    label_encoder=label_encoder,\n",
    "    device=device,\n",
    "    epochs=40,\n",
    "    patience=5,\n",
    "    # freeze_encoder=False,\n",
    "    freeze_epochs=2,\n",
    "    encoder_lr=3e-6,\n",
    "    head_lr=1e-4,  # Para acelerar la adaptaci√≥n de la capa final\n",
    "    gamma=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b313bdfd",
   "metadata": {},
   "source": [
    "#### 4. **FINE TUNING 2/2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89947a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import os\n",
    "import torch, gc\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# A√±adir la ra√≠z del proyecto al path\n",
    "ROOT_DIR = Path.cwd().parent  # <- sube un nivel para alcanzar la ra√≠z del proyecto\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT_DIR))\n",
    "from src.fase2.script_2_transformer_fine_tuning_optimizado import main as fine_tuned_optimized_model\n",
    "\n",
    "# Detectar dispositivo\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# acciones para resolver los problemas de memoria\n",
    "# 1. Liberar memoria\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 2. Optimizar fragmentacion\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(\"üîÑ Restaurando datasets...\")\n",
    "train_dataset = torch.load(\"../data/train/train_dataset.pt\")\n",
    "val_dataset = torch.load(\"../data/train/val_dataset.pt\")\n",
    "\n",
    "# Cargar datasets completos\n",
    "print(\"üîÑ Cargando datasets completos...\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=48, shuffle=True, num_workers=12, pin_memory=True,persistent_workers=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=48, shuffle=False, num_workers=12, pin_memory=True,persistent_workers=True)\n",
    "\n",
    "print(f\"Total batches in train_loader: {len(train_loader)}\")\n",
    "print(f\"Total batches in val_loader: {len(val_loader)}\")\n",
    "\n",
    "label_encoder = pickle.load(open(\"../data/train/label_encoder.pkl\", \"rb\"))\n",
    "num_classes = len(label_encoder)\n",
    "print(f\"NUM CLASES: {num_classes}\")\n",
    "\n",
    "# Fine-tuning adicional\n",
    "# Carga desde mejor_modelo_optimizado.pt\n",
    "# Doble learning rate (encoder / head)\n",
    "# Descongelado tras las primeras n epocas (freeze_epochs=n) o desde el principio (con freeze_encoder=False)\n",
    "# Usar scheduler ReduceLROnPlateau\n",
    "# Optimizaci√≥n por AdamW con weight_decay.\n",
    "print(\"üöÄ Fine-tuning sobre mejor modelo optimizado...\")\n",
    "model = fine_tuned_optimized_model(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    model_name=\"mejor_modelo_finetuned_optimizado2.pt\",\n",
    "    label_encoder=label_encoder,\n",
    "    device=device,\n",
    "    epochs=15,\n",
    "    patience=5,\n",
    "    freeze_encoder=False,\n",
    "    #freeze_epochs=2,\n",
    "    encoder_lr=2e-6,\n",
    "    head_lr=5e-6,\n",
    "    gamma=3,\n",
    "    use_scheduler=True,  # Usar scheduler ReduceLROnPlateau\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ad235-3449-4bf9-9c9b-897025b30f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
