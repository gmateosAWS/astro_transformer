{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155786fb",
   "metadata": {},
   "source": [
    "# 16. Preprocesado: revisi√≥n de la clase YSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0d3598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuraci√≥n de entorno aplicada.\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n general para evitar errores de warnings y compatibilidad\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"RICH_NO_RICH\"] = \"1\"\n",
    "print(\"Configuraci√≥n de entorno aplicada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6969fb91",
   "metadata": {},
   "source": [
    "## NUEVO PREPROCESADO GUARDANDO IDs DE OBJETOS\n",
    "\n",
    "Luego se pueden usar para filtrar curvas dudosas que no est√°n clasificando bien, y as√≠ depurar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac49593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Cargando datos en lotes con PyArrow...\n",
      "‚è≥ [INFO] Iniciando agrupaci√≥n de curvas por objeto...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Agrupando curvas por objeto: 63batch [11:37, 11.08s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ [INFO] Agrupaci√≥n finalizada en 11 minutos y 38.1 segundos\n",
      "üìà [INFO] Total de objetos agrupados: 55439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ [INFO] Agrupaci√≥n guardada en cache: /home/ec2-user/SageMaker/astro_transformer/src/fase2/../../data/train/grouped_data.pkl\n",
      "‚è≥ [INFO] Tiempo en agrupaci√≥n de datos: 708.3 segundos\n",
      "üöÄ Procesando 55439 curvas en paralelo usando 20 CPUs...\n",
      "‚è≥ [INFO] Tiempo en procesamiento paralelo: 70.1 segundos\n",
      "üîã [INFO] Curvas v√°lidas tras filtrado: 55342\n",
      "\n",
      "üîç Realizando prueba r√°pida en caracter√≠sticas auxiliares...\n",
      "‚úÖ Sample 0 sin problemas: [ 0.19635431  0.42738967  0.32871126  0.40973382  0.35245898 -0.55192111\n",
      " -0.31113814]\n",
      "‚úÖ Sample 1 sin problemas: [0.29130239 0.52573524 1.05464936 0.34068212 0.61475402 0.85761099\n",
      " 1.55665765]\n",
      "‚úÖ Sample 2 sin problemas: [0.51674997 0.51286765 1.14926595 0.85981629 0.61475402 0.1469157\n",
      " 0.9786348 ]\n",
      "‚úÖ Sample 3 sin problemas: [-0.19075026 -0.18014706 -0.22838497 -0.14018291 -0.17213115  1.42442416\n",
      "  0.74126081]\n",
      "‚úÖ Sample 4 sin problemas: [ 2.55111529  3.34926441  1.63295259 -0.52537391  3.53278662  0.73290109\n",
      " -0.27647837]\n",
      "‚úÖ Sample 5 sin problemas: [ 6.14331938e-01  5.66176447e-01  6.78629709e-01  7.36064815e-01\n",
      "  6.55737710e-01 -8.44720175e-05  1.37161056e-01]\n",
      "‚úÖ Sample 6 sin problemas: [ 0.54771756  0.398897    0.57096252 -1.37229537  0.49999994 -1.26281257\n",
      "  0.72205251]\n",
      "‚úÖ Sample 7 sin problemas: [-0.27709308 -0.31893381 -0.44698204 -0.68469179 -0.45081964  1.59655251\n",
      "  0.1635658 ]\n",
      "‚úÖ Sample 8 sin problemas: [ 0.65975592  0.79687501  0.47716154 -0.58672997  0.8729507  -0.79390214\n",
      "  0.03630655]\n",
      "‚úÖ Sample 9 sin problemas: [0.05963072 0.10661764 0.11092984 0.43989157 0.05327867 0.50751642\n",
      " 0.39832494]\n",
      "‚úÖ Prueba r√°pida completada.\n",
      "üìÅ Features median y IQR guardados en: /home/ec2-user/SageMaker/astro_transformer/src/fase2/../../data/train/features_stats.pkl\n",
      "[INFO] Uso de memoria de sequences: 10555.65 MB\n",
      "[INFO] Uso de memoria de masks: 10555.65 MB\n",
      "[INFO] Uso de memoria de features: 2.96 MB\n",
      "[INFO] Uso de memoria de labels: 0.21 MB\n",
      "[INFO] N curvas: 55342, seq_length: 25000\n",
      "[INFO] Estimaci√≥n memoria sequences (float16): 2.58 GB\n",
      "[INFO] Estimaci√≥n memoria sequences (float32): 5.15 GB\n",
      "[INFO] Si tienes problemas de memoria, considera usar almacenamiento en disco y Dataset bajo demanda.\n",
      "üíæ [INFO] Guardando label_encoder.pkl...\n",
      "üìä Recuento por clase codificada:\n",
      " 4 (RR Lyrae): 9000\n",
      " 3 (Irregular): 9000\n",
      " 6 (Young Stellar Object): 9799\n",
      " 2 (Eclipsing Binary): 9000\n",
      " 5 (Rotational): 9000\n",
      " 1 (Delta Scuti): 7463\n",
      " 0 (Cataclysmic): 2080\n",
      "üìù [INFO] Realizando split train/val/test...\n",
      "Train: 38739 | Val: 11068 | Test: 5535\n",
      "üìä [INFO] IDs de refuerzo incluidos en train: 0\n",
      "üíæ [INFO] Guardando datasets serializados en formato .pt...\n",
      "\n",
      "üìâ Resumen de curvas descartadas:\n",
      "üî∏ Ok                            : 55342\n",
      "üî∏ Short curve                   : 97\n",
      "‚úÖ Datos preparados como secuencias normalizadas y m√°scaras.\n",
      "‚è≥ [INFO] Tiempo total de ejecuci√≥n: 14.62 minutos (877.5 segundos)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f22c9fe2920>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f22c9fe3be0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# A√±adir la ra√≠z del proyecto al path\n",
    "ROOT_DIR = Path.cwd().parent  # <- sube un nivel para alcanzar la ra√≠z del proyecto\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT_DIR))\n",
    "\n",
    "# Ignorar solo los RuntimeWarning de numpy (como overflows en reduce)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"numpy\")\n",
    "\n",
    "from src.fase2.script_1_transformer_preprocessing_optimizado_2 import main as preprocessing_optimized_with_features\n",
    "\n",
    "max_per_class_override={\n",
    "    \"Irregular\": 9000,\n",
    "    \"Rotational\": 9000,\n",
    "    \"Eclipsing Binary\": 9000,\n",
    "    \"Delta Scuti\": None,            # 7.550 ‚Üí TODAS\n",
    "    \"RR Lyrae\": 9000,               # 41.208 ‚Üí TODAS NO\n",
    "    \"Young Stellar Object\": None,   # 9.809 ‚Üí TODAS\n",
    "    \"Cataclysmic\": None,            # 2.080 ‚Üí TODAS\n",
    "    \"White Dwarf\": 0,               # 0 ‚Üí LA ELIMINAMOS\n",
    "    \"Variable\": 0                   # 0 ‚Üí LA ELIMINAMOS\n",
    "}\n",
    "\n",
    "preprocessing_optimized_with_features(\n",
    "    seq_length=25000,\n",
    "    max_per_class=None, # usamos override completo\n",
    "    max_per_class_override=max_per_class_override,\n",
    "    parquet_batch_size=10_000_000,\n",
    "    dataloader_batch_size=128,\n",
    "    num_workers=20,\n",
    "    filtrar_curvas_malas=None  # ‚Üê NUEVO\n",
    "    #errores_csv_path=Path(\"../outputs/errores_mal_clasificados.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90c6f0",
   "metadata": {},
   "source": [
    "**Script para generar los errores de clasificaci√≥n con los IDs de objeto** \n",
    "\n",
    "Antes no los llevaban. Para ello ejecutamos el `evaluate()` del modelo. \n",
    "La celda anterior fue para repetir el preprocesado ya con los IDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0109fee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N¬∫ de elementos devueltos por __getitem__: 5\n",
      "Elemento 0: <class 'torch.Tensor'>, shape o valor: torch.Size([25000])\n",
      "Elemento 1: <class 'torch.Tensor'>, shape o valor: torch.Size([])\n",
      "Elemento 2: <class 'torch.Tensor'>, shape o valor: torch.Size([25000])\n",
      "Elemento 3: <class 'torch.Tensor'>, shape o valor: torch.Size([7])\n",
      "Elemento 4: <class 'str'>, shape o valor: ASASSN-V J052052.22+025032.8\n",
      "Contenido del label encoder:\n",
      "Cataclysmic: 0\n",
      "Delta Scuti: 1\n",
      "Eclipsing Binary: 2\n",
      "Irregular: 3\n",
      "RR Lyrae: 4\n",
      "Rotational: 5\n",
      "Young Stellar Object: 6\n",
      "\n",
      "üîç Verificaci√≥n manual de los primeros errores:\n",
      "ID: ASASSN-V J052052.22+025032.8\n",
      " - Predicha: Eclipsing Binary\n",
      " - Real (seg√∫n modelo): Eclipsing Binary\n",
      " - Real (en CSV original): Eclipsing Binary\n",
      "---\n",
      "ID: 585366\n",
      " - Predicha: RR Lyrae\n",
      " - Real (seg√∫n modelo): RR Lyrae\n",
      " - Real (en CSV original): RR Lyrae\n",
      "---\n",
      "ID: 205698\n",
      " - Predicha: Delta Scuti\n",
      " - Real (seg√∫n modelo): Delta Scuti\n",
      " - Real (en CSV original): Delta Scuti\n",
      "---\n",
      "ID: ASASSN-V J101123.52-634659.7\n",
      " - Predicha: Rotational\n",
      " - Real (seg√∫n modelo): Rotational\n",
      " - Real (en CSV original): Rotational\n",
      "---\n",
      "ID: ZTFJ020447.04+432503.6\n",
      " - Predicha: Young Stellar Object\n",
      " - Real (seg√∫n modelo): Eclipsing Binary\n",
      " - Real (en CSV original): Eclipsing Binary\n",
      "---\n",
      "YSOs mal clasificadas detectadas: 858\n",
      "Total de errores detectados: 2323\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.serialization\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# A√±adir la ra√≠z del proyecto al path\n",
    "ROOT_DIR = Path.cwd().parent  # <- sube un nivel para alcanzar la ra√≠z del proyecto\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT_DIR))\n",
    "\n",
    "# Ignorar solo los RuntimeWarning de numpy (como overflows en reduce)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"numpy\")\n",
    "\n",
    "from src.fase2.script_2_transformer_fine_tuning_optimizado import AstroConformerClassifier as AstroConformerClassifier, evaluate\n",
    "\n",
    "# Detectar dispositivo\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# acciones para resolver los problemas de memoria\n",
    "# 1. Liberar memoria\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 2. Optimizar fragmentacion\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def detectar_todos_los_errores(preds, true, ids, label_encoder):\n",
    "    \"\"\"\n",
    "    Retorna un DataFrame con todos los errores de clasificaci√≥n con clase real y predicha bien decodificadas.\n",
    "    \"\"\"\n",
    "    df_labels = pd.DataFrame({\n",
    "        \"id_objeto\": ids,\n",
    "        \"true_label\": true,\n",
    "        \"pred_label\": preds\n",
    "    })\n",
    "\n",
    "    # Decodificar nombres\n",
    "    label_decoder = {v: k for k, v in label_encoder.items()}\n",
    "    df_labels[\"clase_real\"] = df_labels[\"true_label\"].map(label_decoder)\n",
    "    df_labels[\"clase_predicha\"] = df_labels[\"pred_label\"].map(label_decoder)\n",
    "\n",
    "    # Filtrar errores\n",
    "    df_errores = df_labels[df_labels[\"clase_real\"] != df_labels[\"clase_predicha\"]][\n",
    "        [\"id_objeto\", \"clase_real\", \"clase_predicha\"]\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    return df_errores\n",
    "\n",
    "def detectar_yso_confundidas(preds, true, ids, label_encoder):\n",
    "    \"\"\"\n",
    "    Retorna un DataFrame con los objetos cuya clase fue predicha como YSO pero no lo eran.\n",
    "    \"\"\"\n",
    "    df_labels = pd.DataFrame({\n",
    "        \"id_objeto\": ids,\n",
    "        \"true_label\": true,\n",
    "        \"pred_label\": preds\n",
    "    })\n",
    "\n",
    "    label_decoder = {v: k for k, v in label_encoder.items()}\n",
    "    df_labels[\"clase_real\"] = df_labels[\"true_label\"].map(label_decoder)\n",
    "    df_labels[\"clase_predicha\"] = df_labels[\"pred_label\"].map(label_decoder)\n",
    "\n",
    "    df_yso_mal = df_labels[\n",
    "        (df_labels[\"clase_predicha\"] == \"Young Stellar Object\") &\n",
    "        (df_labels[\"clase_real\"] != \"Young Stellar Object\")\n",
    "    ][[\"id_objeto\", \"clase_real\", \"clase_predicha\"]].reset_index(drop=True)\n",
    "\n",
    "    return df_yso_mal\n",
    "\n",
    "\n",
    "# Cargar dataset y label encoder\n",
    "from src.fase2.script_1_transformer_preprocessing_optimizado_2 import LightCurveDataset\n",
    "#torch.serialization.add_safe_globals([LightCurveDataset])\n",
    "\n",
    "val_dataset = torch.load(\"../data/train/val_dataset.pt\", weights_only=False)\n",
    "\n",
    "# Verificacion rapida\n",
    "# Cargar un sample cualquiera\n",
    "sample = val_dataset[0]\n",
    "# Ver cu√°ntos elementos contiene\n",
    "print(\"N¬∫ de elementos devueltos por __getitem__:\", len(sample))\n",
    "# Inspeccionar los elementos\n",
    "for i, item in enumerate(sample):\n",
    "    print(f\"Elemento {i}: {type(item)}, shape o valor: {getattr(item, 'shape', item)}\")\n",
    "\n",
    "with open(\"../data/train/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "num_classes = len(label_encoder)\n",
    "class_names = list(label_encoder.keys())\n",
    "\n",
    "# Dataloader con batch peque√±o\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=6, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "# Crear el modelo con la arquitectura esperada\n",
    "args = argparse.Namespace(\n",
    "    input_dim=1,\n",
    "    in_channels=1,\n",
    "    encoder_dim=256,\n",
    "    hidden_dim=384,\n",
    "    output_dim=num_classes,\n",
    "    num_heads=8,\n",
    "    num_layers=8,\n",
    "    dropout=0.4, dropout_p=0.4,\n",
    "    stride=32,\n",
    "    kernel_size=3,\n",
    "    norm=\"postnorm\",\n",
    "    encoder=[\"mhsa_pro\", \"conv\", \"conv\"],\n",
    "    timeshift=False,\n",
    "    device=device\n",
    ")\n",
    "model = AstroConformerClassifier(args, num_classes=len(label_encoder), feature_dim=7)\n",
    "\n",
    "# Cargar los pesos entrenados\n",
    "state_dict = torch.load(\"../outputs/mejor_modelo_finetuned_optimizado2_features_segunda_vuelta.pt\", map_location=\"cpu\")\n",
    "# Elimina el prefijo \"_orig_mod.\" de las claves\n",
    "new_state_dict = {k.replace(\"_orig_mod.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "# Pasar a GPU si est√° disponible\n",
    "model = model.to(device)\n",
    "model.eval()  # Muy importante: modo evaluaci√≥n\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Evaluar con IDs\n",
    "val_loss, preds, true, ids = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "#####################################\n",
    "# Mostrar el label encoder para asegurar consistencia (opcional si ya lo hiciste)\n",
    "print(\"Contenido del label encoder:\")\n",
    "for key, value in label_encoder.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "# Mapear IDs a clases reales desde el CSV original\n",
    "df_debug = pd.read_csv(\"../data/train/debug_clases_codificadas.csv\")\n",
    "dict_clases_reales = dict(zip(df_debug[\"id\"].astype(str), df_debug[\"clase_variable\"]))\n",
    "print(\"\\nüîç Verificaci√≥n manual de los primeros errores:\")\n",
    "for i in range(5):\n",
    "    pred_label = class_names[preds[i]]\n",
    "    true_label = class_names[true[i]]\n",
    "    object_id = str(ids[i])\n",
    "\n",
    "    real_ref = dict_clases_reales.get(object_id, \"NO_ENCONTRADO\")\n",
    "\n",
    "    print(f\"ID: {object_id}\")\n",
    "    print(f\" - Predicha: {pred_label}\")\n",
    "    print(f\" - Real (seg√∫n modelo): {true_label}\")\n",
    "    print(f\" - Real (en CSV original): {real_ref}\")\n",
    "    print(\"---\")\n",
    "#####################################\n",
    "\n",
    "# Detectar YSO mal clasificadas\n",
    "df_yso_mal = detectar_yso_confundidas(preds, true, ids, label_encoder)\n",
    "df_yso_mal.to_csv(\"../outputs/yso_clase_predicha_error.csv\", index=False)\n",
    "# Detectar todos los errores\n",
    "df_todos_errores = detectar_todos_los_errores(preds, true, ids, label_encoder)\n",
    "df_todos_errores.to_csv(\"../outputs/todos_los_errores.csv\", index=False)\n",
    "\n",
    "print(f\"YSOs mal clasificadas detectadas: {len(df_yso_mal)}\")\n",
    "print(f\"Total de errores detectados: {len(df_todos_errores)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36eb772-beb2-4955-b334-03dc2f164b74",
   "metadata": {},
   "source": [
    "#### Verificar que las clases reales en el fichero de errores generado coincide con las clases reales codificadas durante el preprocesado\n",
    "\n",
    "En pruebas anteriores vimos que no estaban igual en ambos sitios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "807b14cf-93b9-44e6-a131-a11256c994f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de errores clasificados: 2323\n",
      "‚ùå Discrepancias entre clase_real y clase_real_ref: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar ambos archivos\n",
    "df_errores = pd.read_csv(\"../outputs/todos_los_errores.csv\")\n",
    "df_ref = pd.read_csv(\"../data/train/debug_clases_codificadas.csv\")\n",
    "\n",
    "# Convertimos nombres para evitar errores\n",
    "df_ref = df_ref.rename(columns={\"id\": \"id_objeto\", \"clase_variable\": \"clase_real_ref\"})\n",
    "\n",
    "# Cruzamos por ID\n",
    "df_merge = pd.merge(df_errores, df_ref, on=\"id_objeto\", how=\"left\")\n",
    "\n",
    "# Comprobamos discrepancias entre la clase_real reportada y la de referencia\n",
    "df_discrepancias = df_merge[df_merge[\"clase_real\"] != df_merge[\"clase_real_ref\"]]\n",
    "\n",
    "# Mostrar resumen\n",
    "print(f\"Total de errores clasificados: {len(df_errores)}\")\n",
    "print(f\"‚ùå Discrepancias entre clase_real y clase_real_ref: {len(df_discrepancias)}\")\n",
    "if not df_discrepancias.empty:\n",
    "    print(df_discrepancias.head())\n",
    "\n",
    "# Guardar discrepancias si las hay\n",
    "df_discrepancias.to_csv(\"../outputs/discrepancias_errores_vs_codificadas.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d378de06-f01c-41e0-97b3-6e92156808a8",
   "metadata": {},
   "source": [
    "#### SCRIPTS PARA EXTRAER LOS CASOS DE CURVAS DUDOSAS QUE SE PODR√çAN ELIMINAR DEL DATASET DE ENTRENAMIENTO\n",
    "\n",
    "Sobre todo a ra√≠z de ver que las YSO, a pesar de ser ahora la clase mayoritaria, es la que m√°s confusiones est√° generando en el modelo, tanto por falsos positivos como por falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc3b4cb-ab6d-4473-9173-fc9b0b7198a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Total de IDs falsos positivos (YSO predicha pero no real): 858\n",
      "üîç Total de IDs falsos negativos (YSO real pero no predicha): 430\n",
      "üî¢ Total YSO reales: 9799\n",
      "‚ö†Ô∏è YSO dudosas detectadas: 430\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar CSV de todas las curvas (con clase real)\n",
    "df_all = pd.read_csv(\"../data/train/debug_clases_codificadas.csv\")\n",
    "\n",
    "# Cargar errores donde se predijo YSO y no lo era (CASO A)\n",
    "df_yso_fp = pd.read_csv(\"../outputs/yso_clase_predicha_error.csv\")\n",
    "ids_fp = set(df_yso_fp[\"id_objeto\"])\n",
    "\n",
    "# Imprimir algunos ejemplos de IDs falsos positivos y el total\n",
    "print(f\"üîç Total de IDs falsos positivos (YSO predicha pero no real): {len(ids_fp)}\")\n",
    "# print(\"üîç Ejemplos de IDs falsos positivos (YSO predicha pero no real):\")\n",
    "# for i, obj_id in enumerate(ids_fp):\n",
    "#     if i < 5:  # Limitar a 5 ejemplos\n",
    "#         print(f\"ID {i+1}: {obj_id}\")\n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "# Cargar errores generales de clasificacion (CASO B)\n",
    "df_errores = pd.read_csv(\"../outputs/todos_los_errores.csv\")\n",
    "\n",
    "# A√±adir ID si est√° disponible (debes tener otro CSV con √≠ndices ‚Üí IDs si no lo incluiste)\n",
    "# Aqu√≠ asumimos que ya tienes columna \"id_objeto\" cruzada\n",
    "df_fn_yso = df_errores[\n",
    "    df_errores[\"clase_real\"] == \"Young Stellar Object\"\n",
    "].copy()\n",
    "ids_fn = set(df_fn_yso[\"id_objeto\"])\n",
    "\n",
    "# Imprimir algunos ejemplos de IDs falsos negativos y el total\n",
    "print(f\"üîç Total de IDs falsos negativos (YSO real pero no predicha): {len(ids_fn)}\")\n",
    "# print(\"üîç Ejemplos de IDs falsos negativos (YSO real pero no predicha):\")\n",
    "# for i, obj_id in enumerate(ids_fn):\n",
    "#     if i < 5:  # Limitar a 5 ejemplos\n",
    "#         print(f\"ID {i+1}: {obj_id}\")\n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "# üîÅ CURVAS QUE QUEREMOS DEPURAR = uni√≥n de ambas\n",
    "ids_dudosos = ids_fp.union(ids_fn)\n",
    "\n",
    "# Imrpimir algunos ejemplos de IDs dudosos\n",
    "# print(\"üîç Ejemplos de IDs dudosos:\" )\n",
    "# for i, obj_id in enumerate(ids_dudosos):\n",
    "#     if i < 5:  # Limitar a 5 ejemplos\n",
    "#         print(f\"ID {i+1}: {obj_id}\")\n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "# Filtrar todas las YSO reales del dataset original\n",
    "df_yso_all = df_all[df_all[\"clase_variable\"] == \"Young Stellar Object\"].copy()\n",
    "\n",
    "# Marcar cu√°les son dudosas\n",
    "df_yso_all[\"dudosa\"] = df_yso_all[\"id\"].isin(ids_dudosos)\n",
    "\n",
    "# Estad√≠sticas\n",
    "print(f\"üî¢ Total YSO reales: {len(df_yso_all)}\")\n",
    "print(f\"‚ö†Ô∏è YSO dudosas detectadas: {df_yso_all['dudosa'].sum()}\")\n",
    "\n",
    "# Ordenar para dejar las seguras primero\n",
    "df_yso_ordenadas = df_yso_all.sort_values(by=\"dudosa\", ascending=True)\n",
    "\n",
    "# Seleccionar 9000 curvas m√°s confiables\n",
    "df_yso_final = df_yso_ordenadas.head(9000).copy()\n",
    "\n",
    "# Guardar resultado\n",
    "#df_yso_final.to_csv(\"../data/train/ysos_9000_filtradas_seguras.csv\", index=False)\n",
    "#print(\"‚úÖ Guardado en outputs/ysos_9000_filtradas_seguras.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b88a96d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Total de FALSOS NEGATIVOS (YSO reales pero no predichas): 430\n",
      "üîç Total de FALSOS POSITIVOS (YSO predichas pero no reales): 858\n",
      "üîç Total de curvas a eliminar: 1288\n",
      "motivo_descarte\n",
      "YSO predicha incorrectamente (FP)    858\n",
      "YSO mal clasificada (FN)             430\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä Desglose por clase original (impacto en dataset):\n",
      "clase_original\n",
      "Young Stellar Object    430\n",
      "Eclipsing Binary        238\n",
      "Cataclysmic             195\n",
      "Rotational              170\n",
      "RR Lyrae                101\n",
      "Delta Scuti              97\n",
      "Irregular                57\n",
      "Name: count, dtype: int64\n",
      "‚úÖ Guardado en: ../data/train/curvas_a_eliminar_por_confusion_yso.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Cargar CSV de todas las curvas con su clase real\n",
    "df_all = pd.read_csv(\"../data/train/debug_clases_codificadas.csv\")\n",
    "\n",
    "# 2. FALSOS NEGATIVOS: eran YSO pero el modelo no las predijo como tal\n",
    "df_errores = pd.read_csv(\"../outputs/todos_los_errores.csv\")\n",
    "df_fn = df_errores[df_errores[\"clase_real\"] == \"Young Stellar Object\"].copy()\n",
    "df_fn[\"motivo_descarte\"] = \"YSO mal clasificada (FN)\"\n",
    "df_fn = df_fn[[\"id_objeto\", \"clase_real\", \"motivo_descarte\"]]\n",
    "df_fn.rename(columns={\"clase_real\": \"clase_original\"}, inplace=True)\n",
    "# Imprimir total de FN\n",
    "print(f\"üîç Total de FALSOS NEGATIVOS (YSO reales pero no predichas): {len(df_fn)}\")\n",
    "\n",
    "# 3. FALSOS POSITIVOS: no eran YSO pero el modelo las predijo como YSO\n",
    "df_fp = pd.read_csv(\"../outputs/yso_clase_predicha_error.csv\")\n",
    "df_fp[\"motivo_descarte\"] = \"YSO predicha incorrectamente (FP)\"\n",
    "df_fp.rename(columns={\"clase_real\": \"clase_original\", \"id\": \"id_objeto\"}, inplace=True)\n",
    "df_fp = df_fp[[\"id_objeto\", \"clase_original\", \"motivo_descarte\"]]\n",
    "# Imprimir total de FP\n",
    "print(f\"üîç Total de FALSOS POSITIVOS (YSO predichas pero no reales): {len(df_fp)}\")\n",
    "\n",
    "# 4. Unir ambos\n",
    "df_dudosos = pd.concat([df_fn, df_fp], ignore_index=True)\n",
    "\n",
    "# 5. Verificar qu√© porcentaje representan\n",
    "print(f\"üîç Total de curvas a eliminar: {len(df_dudosos)}\")\n",
    "print(df_dudosos[\"motivo_descarte\"].value_counts())\n",
    "\n",
    "# 6. A√±adir columna auxiliar para posibles an√°lisis\n",
    "df_dudosos[\"origen\"] = df_dudosos[\"id_objeto\"].apply(\n",
    "    lambda x: \"ASASSN\" if \"ASASSN\" in x else \"ZTF\" if \"ZTF\" in x else \"TESS\" if \"TIC_\" in x else \"Otros\"\n",
    ")\n",
    "\n",
    "# 7. Generar desglose por clase real\n",
    "print(\"\\nüìä Desglose por clase original (impacto en dataset):\")\n",
    "print(df_dudosos[\"clase_original\"].value_counts())\n",
    "\n",
    "# 8. Guardar CSV de curvas a eliminar\n",
    "df_dudosos.to_csv(\"../data/train/curvas_a_eliminar_por_confusion_yso.csv\", index=False)\n",
    "print(\"‚úÖ Guardado en: ../data/train/curvas_a_eliminar_por_confusion_yso.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4468026a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ [INFO] IDs a excluir por filtrado: 1288\n",
      "üìÇ [INFO] Exclusiones por clase: {'Cataclysmic': 195, 'Delta Scuti': 97, 'Eclipsing Binary': 238, 'Irregular': 57, 'RR Lyrae': 101, 'Rotational': 170, 'Young Stellar Object': 430}\n"
     ]
    }
   ],
   "source": [
    "max_per_class_override={\n",
    "    \"Irregular\": 9000,\n",
    "    \"Rotational\": 9000,\n",
    "    \"Eclipsing Binary\": 9000,\n",
    "    \"Delta Scuti\": None, # 7.550 ‚Üí TODAS\n",
    "    \"RR Lyrae\": 9000, # 41.208 ‚Üí TODAS NO\n",
    "    \"Young Stellar Object\": None, # 9.809 ‚Üí TODAS\n",
    "    \"Cataclysmic\": None, # 2.080 ‚Üí TODAS\n",
    "    \"White Dwarf\": 0, # 0 ‚Üí LA ELIMINAMOS\n",
    "    \"Variable\": 0 # 0 ‚Üí LA ELIMINAMOS\n",
    "}\n",
    "max_per_class = None  # Si no hay override, usamos el global\n",
    "\n",
    "df_malas = pd.read_csv(\"../data/train/curvas_a_eliminar_por_confusion_yso.csv\")\n",
    "ids_a_excluir = set(df_malas[\"id_objeto\"].astype(str))\n",
    "# Contar por clase original\n",
    "ids_a_excluir_por_clase = df_malas.groupby(\"clase_original\")[\"id_objeto\"].nunique().to_dict()\n",
    "print(f\"\\U0001F4C2 [INFO] IDs a excluir por filtrado: {len(ids_a_excluir)}\")\n",
    "print(f\"\\U0001F4C2 [INFO] Exclusiones por clase: {ids_a_excluir_por_clase}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce9017-15d5-4d94-a785-0e7697e6e373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
