{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155786fb",
   "metadata": {},
   "source": [
    "# 16. Preprocesado: revisi√≥n de la clase YSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0d3598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuraci√≥n de entorno aplicada.\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n general para evitar errores de warnings y compatibilidad\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"RICH_NO_RICH\"] = \"1\"\n",
    "print(\"Configuraci√≥n de entorno aplicada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6969fb91",
   "metadata": {},
   "source": [
    "## NUEVO PREPROCESADO GUARDANDO IDs DE OBJETOS\n",
    "\n",
    "Luego se pueden usar para filtrar curvas dudosas que no est√°n clasificando bien, y as√≠ depurar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac49593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Cargando datos en lotes con PyArrow...\n",
      "üíæ [INFO] Cargando agrupaci√≥n de curvas desde cache: /home/ec2-user/SageMaker/astro_transformer/src/fase2/../../data/train/grouped_data.pkl\n",
      "‚úÖ [INFO] Agrupaci√≥n cargada desde cache. Total objetos: 55439\n",
      "‚è≥ [INFO] Tiempo en agrupaci√≥n de datos: 10.9 segundos\n",
      "üöÄ Procesando 55439 curvas en paralelo usando 20 CPUs...\n",
      "‚è≥ [INFO] Tiempo en procesamiento paralelo: 82.2 segundos\n",
      "üîã [INFO] Curvas v√°lidas tras filtrado: 55342\n",
      "\n",
      "üîç Realizando prueba r√°pida en caracter√≠sticas auxiliares...\n",
      "‚úÖ Sample 0 sin problemas: [-0.54765874 -0.46691176 -0.58238172 -0.45465844 -0.48360653 -0.18917597\n",
      "  0.26550589]\n",
      "‚úÖ Sample 1 sin problemas: [-0.31123622 -0.23529412 -0.42088094 -0.30324447 -0.22950819  0.35237014\n",
      " -0.16461357]\n",
      "‚úÖ Sample 2 sin problemas: [-0.50290883 -0.43382352 -0.54812398 -0.73793606 -0.4426229  -0.35511186\n",
      " -0.06430592]\n",
      "‚úÖ Sample 3 sin problemas: [ 1.37089379  1.63602933  0.83931489 -1.24292777  1.21311469 -1.06736809\n",
      " -0.27657237]\n",
      "‚úÖ Sample 4 sin problemas: [-0.13150858  0.07536761 -0.32218598 -0.43718764  0.0942623   0.37391438\n",
      " -0.49674234]\n",
      "‚úÖ Sample 5 sin problemas: [-0.33489974 -0.30147059 -0.26835236 -1.38727051 -0.30327867  0.46031976\n",
      "  0.67637753]\n",
      "‚úÖ Sample 6 sin problemas: [ 0.78642899  0.94485279  0.51957583 -0.43427584  0.85245892 -1.17465803\n",
      " -0.05892404]\n",
      "‚úÖ Sample 7 sin problemas: [-0.54369489 -0.47058824 -0.58727572 -0.90474131 -0.48360653  0.40456442\n",
      "  0.02911986]\n",
      "‚úÖ Sample 8 sin problemas: [ 0.41094463  0.64705874  0.53344213  0.77953393  0.76229505  0.2181877\n",
      " -0.23647418]\n",
      "‚úÖ Sample 9 sin problemas: [ 0.80021573  1.13327205  0.21044047  0.14496675  0.77049179 -1.01843543\n",
      " -0.3953826 ]\n",
      "‚úÖ Prueba r√°pida completada.\n",
      "üìÅ Features median y IQR guardados en: /home/ec2-user/SageMaker/astro_transformer/src/fase2/../../data/train/features_stats.pkl\n",
      "[INFO] Uso de memoria de sequences: 10555.65 MB\n",
      "[INFO] Uso de memoria de masks: 10555.65 MB\n",
      "[INFO] Uso de memoria de features: 2.96 MB\n",
      "[INFO] Uso de memoria de labels: 0.21 MB\n",
      "[INFO] N curvas: 55342, seq_length: 25000\n",
      "[INFO] Estimaci√≥n memoria sequences (float16): 2.58 GB\n",
      "[INFO] Estimaci√≥n memoria sequences (float32): 5.15 GB\n",
      "[INFO] Si tienes problemas de memoria, considera usar almacenamiento en disco y Dataset bajo demanda.\n",
      "üíæ [INFO] Guardando label_encoder.pkl...\n",
      "üìä Recuento por clase codificada:\n",
      " 5 (Rotational): 9000\n",
      " 3 (Irregular): 9000\n",
      " 4 (RR Lyrae): 9000\n",
      " 2 (Eclipsing Binary): 9000\n",
      " 6 (Young Stellar Object): 9799\n",
      " 0 (Cataclysmic): 2080\n",
      " 1 (Delta Scuti): 7463\n",
      "üìù [INFO] Realizando split train/val/test...\n",
      "Train: 38739 | Val: 11068 | Test: 5535\n",
      "üìä [INFO] IDs de refuerzo incluidos en train: 0\n",
      "üíæ [INFO] Guardando datasets serializados en formato .pt...\n",
      "\n",
      "üìâ Resumen de curvas descartadas:\n",
      "üî∏ Ok                            : 55342\n",
      "üî∏ Short curve                   : 97\n",
      "‚úÖ Datos preparados como secuencias normalizadas y m√°scaras.\n",
      "‚è≥ [INFO] Tiempo total de ejecuci√≥n: 4.35 minutos (260.8 segundos)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f1cae76d5d0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1cae76e3b0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# A√±adir la ra√≠z del proyecto al path\n",
    "ROOT_DIR = Path.cwd().parent  # <- sube un nivel para alcanzar la ra√≠z del proyecto\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT_DIR))\n",
    "\n",
    "# Ignorar solo los RuntimeWarning de numpy (como overflows en reduce)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"numpy\")\n",
    "\n",
    "from src.fase2.script_1_transformer_preprocessing_optimizado_2 import main as preprocessing_optimized_with_features\n",
    "\n",
    "max_per_class_override={\n",
    "    \"Irregular\": 9000,\n",
    "    \"Rotational\": 9000,\n",
    "    \"Eclipsing Binary\": 9000,\n",
    "    \"Delta Scuti\": None,            # 7.550 ‚Üí TODAS\n",
    "    \"RR Lyrae\": 9000,               # 41.208 ‚Üí TODAS NO\n",
    "    \"Young Stellar Object\": None,   # 9.809 ‚Üí TODAS\n",
    "    \"Cataclysmic\": None,            # 2.080 ‚Üí TODAS\n",
    "    \"White Dwarf\": 0,               # 0 ‚Üí LA ELIMINAMOS\n",
    "    \"Variable\": 0                   # 0 ‚Üí LA ELIMINAMOS\n",
    "}\n",
    "\n",
    "preprocessing_optimized_with_features(\n",
    "    seq_length=25000,\n",
    "    max_per_class=None, # usamos override completo\n",
    "    max_per_class_override=max_per_class_override,\n",
    "    parquet_batch_size=10_000_000,\n",
    "    dataloader_batch_size=128,\n",
    "    num_workers=20,\n",
    "    #errores_csv_path=Path(\"../outputs/errores_mal_clasificados.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90c6f0",
   "metadata": {},
   "source": [
    "**Con el siguiente script intentamos detectar los IDs de las curvas YSO que est√°n confundiendo al modelo**.\n",
    "\n",
    "En la matriz de confusi√≥n vimos muchos casos de clase predicha YSO que en realidad era cualquiera de las otras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0109fee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N¬∫ de elementos devueltos por __getitem__: 5\n",
      "Elemento 0: <class 'torch.Tensor'>, shape o valor: torch.Size([25000])\n",
      "Elemento 1: <class 'torch.Tensor'>, shape o valor: torch.Size([])\n",
      "Elemento 2: <class 'torch.Tensor'>, shape o valor: torch.Size([25000])\n",
      "Elemento 3: <class 'torch.Tensor'>, shape o valor: torch.Size([7])\n",
      "Elemento 4: <class 'str'>, shape o valor: AP28318078\n",
      "YSOs mal clasificadas detectadas: 868\n",
      "Total de errores detectados: 2349\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.serialization\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# A√±adir la ra√≠z del proyecto al path\n",
    "ROOT_DIR = Path.cwd().parent  # <- sube un nivel para alcanzar la ra√≠z del proyecto\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT_DIR))\n",
    "\n",
    "# Ignorar solo los RuntimeWarning de numpy (como overflows en reduce)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"numpy\")\n",
    "\n",
    "from src.fase2.script_2_transformer_fine_tuning_optimizado import AstroConformerClassifier as AstroConformerClassifier, evaluate\n",
    "\n",
    "# Detectar dispositivo\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# acciones para resolver los problemas de memoria\n",
    "# 1. Liberar memoria\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 2. Optimizar fragmentacion\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def detectar_yso_confundidas(preds, true, ids, label_encoder):\n",
    "    \"\"\"\n",
    "    Retorna un DataFrame con los objetos cuya clase fue predicha como YSO,\n",
    "    pero su clase real era diferente.\n",
    "    \"\"\"\n",
    "    inv_label_encoder = {v: k for k, v in label_encoder.items()}\n",
    "\n",
    "    errores = []\n",
    "    for pred, real, obj_id in zip(preds, true, ids):\n",
    "        clase_pred = inv_label_encoder[pred]\n",
    "        clase_real = inv_label_encoder[real]\n",
    "        if clase_pred == \"Young Stellar Object\" and clase_real != \"Young Stellar Object\":\n",
    "            errores.append({\"id_objeto\": obj_id, \"clase_real\": clase_real, \"clase_predicha\": clase_pred})\n",
    "\n",
    "    return pd.DataFrame(errores)\n",
    "\n",
    "def detectar_todos_los_errores(preds, true, ids, label_encoder):\n",
    "    \"\"\"\n",
    "    Retorna un DataFrame con todos los objetos cuya clase predicha es diferente a la real.\n",
    "    \"\"\"\n",
    "    inv_label_encoder = {v: k for k, v in label_encoder.items()}\n",
    "\n",
    "    errores = []\n",
    "    for pred, real, obj_id in zip(preds, true, ids):\n",
    "        clase_pred = inv_label_encoder[pred]\n",
    "        clase_real = inv_label_encoder[real]\n",
    "        if clase_pred != clase_real:\n",
    "            errores.append({\"id_objeto\": obj_id, \"clase_real\": clase_real, \"clase_predicha\": clase_pred})\n",
    "\n",
    "    return pd.DataFrame(errores)\n",
    "\n",
    "\n",
    "# Cargar dataset y label encoder\n",
    "from src.fase2.script_1_transformer_preprocessing_optimizado_2 import LightCurveDataset\n",
    "#torch.serialization.add_safe_globals([LightCurveDataset])\n",
    "\n",
    "val_dataset = torch.load(\"../data/train/val_dataset.pt\", weights_only=False)\n",
    "\n",
    "# Verificacion rapida\n",
    "# Cargar un sample cualquiera\n",
    "sample = val_dataset[0]\n",
    "# Ver cu√°ntos elementos contiene\n",
    "print(\"N¬∫ de elementos devueltos por __getitem__:\", len(sample))\n",
    "# Inspeccionar los elementos\n",
    "for i, item in enumerate(sample):\n",
    "    print(f\"Elemento {i}: {type(item)}, shape o valor: {getattr(item, 'shape', item)}\")\n",
    "\n",
    "with open(\"../data/train/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "num_classes = len(label_encoder)\n",
    "class_names = list(label_encoder.keys())\n",
    "\n",
    "# Dataloader con batch peque√±o\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=6, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "# Crear el modelo con la arquitectura esperada\n",
    "args = argparse.Namespace(\n",
    "    input_dim=1,\n",
    "    in_channels=1,\n",
    "    encoder_dim=256,\n",
    "    hidden_dim=384,\n",
    "    output_dim=num_classes,\n",
    "    num_heads=8,\n",
    "    num_layers=8,\n",
    "    dropout=0.4, dropout_p=0.4,\n",
    "    stride=32,\n",
    "    kernel_size=3,\n",
    "    norm=\"postnorm\",\n",
    "    encoder=[\"mhsa_pro\", \"conv\", \"conv\"],\n",
    "    timeshift=False,\n",
    "    device=device\n",
    ")\n",
    "model = AstroConformerClassifier(args, num_classes=len(label_encoder), feature_dim=7)\n",
    "\n",
    "# Cargar los pesos entrenados\n",
    "state_dict = torch.load(\"../outputs/mejor_modelo_finetuned_optimizado2_features_segunda_vuelta.pt\", map_location=\"cpu\")\n",
    "# Elimina el prefijo \"_orig_mod.\" de las claves\n",
    "new_state_dict = {k.replace(\"_orig_mod.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "# Pasar a GPU si est√° disponible\n",
    "model = model.to(device)\n",
    "model.eval()  # Muy importante: modo evaluaci√≥n\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Evaluar con IDs\n",
    "val_loss, preds, true, ids = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "# Detectar YSO mal clasificadas\n",
    "df_yso_mal = detectar_yso_confundidas(preds, true, ids, label_encoder)\n",
    "df_yso_mal.to_csv(\"../outputs/yso_clase_predicha_error.csv\", index=False)\n",
    "# Detectar todos los errores\n",
    "df_todos_errores = detectar_todos_los_errores(preds, true, ids, label_encoder)\n",
    "df_todos_errores.to_csv(\"../outputs/todos_los_errores.csv\", index=False)\n",
    "\n",
    "print(f\"YSOs mal clasificadas detectadas: {len(df_yso_mal)}\")\n",
    "print(f\"Total de errores detectados: {len(df_todos_errores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc3b4cb-ab6d-4473-9173-fc9b0b7198a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Ejemplos de IDs falsos positivos (YSO predicha pero no real):\n",
      "ID 1: ASASSN-V J025637.39+260456.2\n",
      "ID 2: ZTFJ032204.91+445907.8\n",
      "ID 3: TIC_346741139.0\n",
      "ID 4: ASASSN-V J040855.11-421656.9\n",
      "ID 5: ASASSN-V J232708.21+371216.7\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'id_objeto'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hav3f\\anaconda3\\envs\\astro_transformer\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'id_objeto'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# A√±adir ID si est√° disponible (debes tener otro CSV con √≠ndices ‚Üí IDs si no lo incluiste)\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Aqu√≠ asumimos que ya tienes columna \"id_objeto\" cruzada\u001b[39;00m\n\u001b[32m     23\u001b[39m df_fn_yso = df_errores[\n\u001b[32m     24\u001b[39m     df_errores[\u001b[33m\"\u001b[39m\u001b[33mclase_real\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mYoung Stellar Object\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     25\u001b[39m ].copy()\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m ids_fn = \u001b[38;5;28mset\u001b[39m(\u001b[43mdf_fn_yso\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mid_objeto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Imprimir algunos ejemplos de IDs falsos negativos\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîç Ejemplos de IDs falsos negativos (YSO real pero no predicha):\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hav3f\\anaconda3\\envs\\astro_transformer\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hav3f\\anaconda3\\envs\\astro_transformer\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'id_objeto'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar CSV de todas las curvas (con clase real)\n",
    "df_all = pd.read_csv(\"../data/train/debug_clases_codificadas.csv\")\n",
    "\n",
    "# Cargar errores donde se predijo YSO y no lo era (CASO A)\n",
    "df_yso_fp = pd.read_csv(\"../outputs/yso_clase_predicha_error.csv\")\n",
    "ids_fp = set(df_yso_fp[\"id_objeto\"])\n",
    "\n",
    "# Imprimir algunos ejemplos de IDs falsos positivos\n",
    "print(\"üîç Ejemplos de IDs falsos positivos (YSO predicha pero no real):\")\n",
    "for i, obj_id in enumerate(ids_fp):\n",
    "    if i < 5:  # Limitar a 5 ejemplos\n",
    "        print(f\"ID {i+1}: {obj_id}\")\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Cargar errores generales de clasificacion (CASO B)\n",
    "df_errores = pd.read_csv(\"../outputs/todos_los_errores.csv\")\n",
    "\n",
    "# A√±adir ID si est√° disponible (debes tener otro CSV con √≠ndices ‚Üí IDs si no lo incluiste)\n",
    "# Aqu√≠ asumimos que ya tienes columna \"id_objeto\" cruzada\n",
    "df_fn_yso = df_errores[\n",
    "    df_errores[\"clase_real\"] == \"Young Stellar Object\"\n",
    "].copy()\n",
    "ids_fn = set(df_fn_yso[\"id_objeto\"])\n",
    "# Imprimir algunos ejemplos de IDs falsos negativos\n",
    "print(\"üîç Ejemplos de IDs falsos negativos (YSO real pero no predicha):\")\n",
    "for i, obj_id in enumerate(ids_fn):\n",
    "    if i < 5:  # Limitar a 5 ejemplos\n",
    "        print(f\"ID {i+1}: {obj_id}\")\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# üîÅ CURVAS QUE QUEREMOS DEPURAR = uni√≥n de ambas\n",
    "ids_dudosos = ids_fp.union(ids_fn)\n",
    "\n",
    "# Imrpimir algunos ejemplos de IDs dudosos\n",
    "print(\"üîç Ejemplos de IDs dudosos:\" )\n",
    "for i, obj_id in enumerate(ids_dudosos):\n",
    "    if i < 5:  # Limitar a 5 ejemplos\n",
    "        print(f\"ID {i+1}: {obj_id}\")\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Filtrar todas las YSO reales del dataset original\n",
    "df_yso_all = df_all[df_all[\"clase_variable_normalizada\"] == \"Young Stellar Object\"].copy()\n",
    "\n",
    "# Marcar cu√°les son dudosas\n",
    "df_yso_all[\"dudosa\"] = df_yso_all[\"id\"].isin(ids_dudosos)\n",
    "\n",
    "# Estad√≠sticas\n",
    "print(f\"üî¢ Total YSO reales: {len(df_yso_all)}\")\n",
    "print(f\"‚ö†Ô∏è YSO dudosas detectadas: {df_yso_all['dudosa'].sum()}\")\n",
    "\n",
    "# Ordenar para dejar las seguras primero\n",
    "df_yso_ordenadas = df_yso_all.sort_values(by=\"dudosa\", ascending=True)\n",
    "\n",
    "# Seleccionar 9000 curvas m√°s confiables\n",
    "df_yso_final = df_yso_ordenadas.head(9000).copy()\n",
    "\n",
    "# Guardar resultado\n",
    "df_yso_final.to_csv(\"../data/train/ysos_9000_filtradas_seguras.csv\", index=False)\n",
    "print(\"‚úÖ Guardado en outputs/ysos_9000_filtradas_seguras.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
