{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155786fb",
   "metadata": {},
   "source": [
    "# 16. Preprocesado: revisi√≥n de la clase YSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0d3598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuraci√≥n de entorno aplicada.\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n general para evitar errores de warnings y compatibilidad\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"RICH_NO_RICH\"] = \"1\"\n",
    "print(\"Configuraci√≥n de entorno aplicada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6969fb91",
   "metadata": {},
   "source": [
    "## NUEVO PREPROCESADO GUARDANDO IDs DE OBJETOS\n",
    "\n",
    "Luego se pueden usar para filtrar curvas dudosas que no est√°n clasificando bien, y as√≠ depurar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac49593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Cargando datos en lotes con PyArrow...\n",
      "üíæ [INFO] Cargando agrupaci√≥n de curvas desde cache: /home/ec2-user/SageMaker/astro_transformer/src/fase2/../../data/train/grouped_data.pkl\n",
      "‚úÖ [INFO] Agrupaci√≥n cargada desde cache. Total objetos: 55439\n",
      "‚è≥ [INFO] Tiempo en agrupaci√≥n de datos: 10.9 segundos\n",
      "üöÄ Procesando 55439 curvas en paralelo usando 20 CPUs...\n",
      "‚è≥ [INFO] Tiempo en procesamiento paralelo: 82.2 segundos\n",
      "üîã [INFO] Curvas v√°lidas tras filtrado: 55342\n",
      "\n",
      "üîç Realizando prueba r√°pida en caracter√≠sticas auxiliares...\n",
      "‚úÖ Sample 0 sin problemas: [-0.54765874 -0.46691176 -0.58238172 -0.45465844 -0.48360653 -0.18917597\n",
      "  0.26550589]\n",
      "‚úÖ Sample 1 sin problemas: [-0.31123622 -0.23529412 -0.42088094 -0.30324447 -0.22950819  0.35237014\n",
      " -0.16461357]\n",
      "‚úÖ Sample 2 sin problemas: [-0.50290883 -0.43382352 -0.54812398 -0.73793606 -0.4426229  -0.35511186\n",
      " -0.06430592]\n",
      "‚úÖ Sample 3 sin problemas: [ 1.37089379  1.63602933  0.83931489 -1.24292777  1.21311469 -1.06736809\n",
      " -0.27657237]\n",
      "‚úÖ Sample 4 sin problemas: [-0.13150858  0.07536761 -0.32218598 -0.43718764  0.0942623   0.37391438\n",
      " -0.49674234]\n",
      "‚úÖ Sample 5 sin problemas: [-0.33489974 -0.30147059 -0.26835236 -1.38727051 -0.30327867  0.46031976\n",
      "  0.67637753]\n",
      "‚úÖ Sample 6 sin problemas: [ 0.78642899  0.94485279  0.51957583 -0.43427584  0.85245892 -1.17465803\n",
      " -0.05892404]\n",
      "‚úÖ Sample 7 sin problemas: [-0.54369489 -0.47058824 -0.58727572 -0.90474131 -0.48360653  0.40456442\n",
      "  0.02911986]\n",
      "‚úÖ Sample 8 sin problemas: [ 0.41094463  0.64705874  0.53344213  0.77953393  0.76229505  0.2181877\n",
      " -0.23647418]\n",
      "‚úÖ Sample 9 sin problemas: [ 0.80021573  1.13327205  0.21044047  0.14496675  0.77049179 -1.01843543\n",
      " -0.3953826 ]\n",
      "‚úÖ Prueba r√°pida completada.\n",
      "üìÅ Features median y IQR guardados en: /home/ec2-user/SageMaker/astro_transformer/src/fase2/../../data/train/features_stats.pkl\n",
      "[INFO] Uso de memoria de sequences: 10555.65 MB\n",
      "[INFO] Uso de memoria de masks: 10555.65 MB\n",
      "[INFO] Uso de memoria de features: 2.96 MB\n",
      "[INFO] Uso de memoria de labels: 0.21 MB\n",
      "[INFO] N curvas: 55342, seq_length: 25000\n",
      "[INFO] Estimaci√≥n memoria sequences (float16): 2.58 GB\n",
      "[INFO] Estimaci√≥n memoria sequences (float32): 5.15 GB\n",
      "[INFO] Si tienes problemas de memoria, considera usar almacenamiento en disco y Dataset bajo demanda.\n",
      "üíæ [INFO] Guardando label_encoder.pkl...\n",
      "üìä Recuento por clase codificada:\n",
      " 5 (Rotational): 9000\n",
      " 3 (Irregular): 9000\n",
      " 4 (RR Lyrae): 9000\n",
      " 2 (Eclipsing Binary): 9000\n",
      " 6 (Young Stellar Object): 9799\n",
      " 0 (Cataclysmic): 2080\n",
      " 1 (Delta Scuti): 7463\n",
      "üìù [INFO] Realizando split train/val/test...\n",
      "Train: 38739 | Val: 11068 | Test: 5535\n",
      "üìä [INFO] IDs de refuerzo incluidos en train: 0\n",
      "üíæ [INFO] Guardando datasets serializados en formato .pt...\n",
      "\n",
      "üìâ Resumen de curvas descartadas:\n",
      "üî∏ Ok                            : 55342\n",
      "üî∏ Short curve                   : 97\n",
      "‚úÖ Datos preparados como secuencias normalizadas y m√°scaras.\n",
      "‚è≥ [INFO] Tiempo total de ejecuci√≥n: 4.35 minutos (260.8 segundos)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f1cae76d5d0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1cae76e3b0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# A√±adir la ra√≠z del proyecto al path\n",
    "ROOT_DIR = Path.cwd().parent  # <- sube un nivel para alcanzar la ra√≠z del proyecto\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT_DIR))\n",
    "\n",
    "# Ignorar solo los RuntimeWarning de numpy (como overflows en reduce)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"numpy\")\n",
    "\n",
    "from src.fase2.script_1_transformer_preprocessing_optimizado_2 import main as preprocessing_optimized_with_features\n",
    "\n",
    "max_per_class_override={\n",
    "    \"Irregular\": 9000,\n",
    "    \"Rotational\": 9000,\n",
    "    \"Eclipsing Binary\": 9000,\n",
    "    \"Delta Scuti\": None,            # 7.550 ‚Üí TODAS\n",
    "    \"RR Lyrae\": 9000,               # 41.208 ‚Üí TODAS NO\n",
    "    \"Young Stellar Object\": None,   # 9.809 ‚Üí TODAS\n",
    "    \"Cataclysmic\": None,            # 2.080 ‚Üí TODAS\n",
    "    \"White Dwarf\": 0,               # 0 ‚Üí LA ELIMINAMOS\n",
    "    \"Variable\": 0                   # 0 ‚Üí LA ELIMINAMOS\n",
    "}\n",
    "\n",
    "preprocessing_optimized_with_features(\n",
    "    seq_length=25000,\n",
    "    max_per_class=None, # usamos override completo\n",
    "    max_per_class_override=max_per_class_override,\n",
    "    parquet_batch_size=10_000_000,\n",
    "    dataloader_batch_size=128,\n",
    "    num_workers=20,\n",
    "    #errores_csv_path=Path(\"../outputs/errores_mal_clasificados.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90c6f0",
   "metadata": {},
   "source": [
    "**Con el siguiente script intentamos detectar los IDs de las curvas YSO que est√°n confundiendo al modelo**.\n",
    "\n",
    "En la matriz de confusi√≥n vimos muchos casos de clase predicha YSO que en realidad era cualquiera de las otras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0109fee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N¬∫ de elementos devueltos por __getitem__: 5\n",
      "Elemento 0: <class 'torch.Tensor'>, shape o valor: torch.Size([25000])\n",
      "Elemento 1: <class 'torch.Tensor'>, shape o valor: torch.Size([])\n",
      "Elemento 2: <class 'torch.Tensor'>, shape o valor: torch.Size([25000])\n",
      "Elemento 3: <class 'torch.Tensor'>, shape o valor: torch.Size([7])\n",
      "Elemento 4: <class 'str'>, shape o valor: AP28318078\n",
      "YSOs mal clasificadas detectadas: 868\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.serialization\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# A√±adir la ra√≠z del proyecto al path\n",
    "ROOT_DIR = Path.cwd().parent  # <- sube un nivel para alcanzar la ra√≠z del proyecto\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT_DIR))\n",
    "\n",
    "# Ignorar solo los RuntimeWarning de numpy (como overflows en reduce)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"numpy\")\n",
    "\n",
    "from src.fase2.script_2_transformer_fine_tuning_optimizado import AstroConformerClassifier as AstroConformerClassifier, evaluate\n",
    "\n",
    "# Detectar dispositivo\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# acciones para resolver los problemas de memoria\n",
    "# 1. Liberar memoria\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 2. Optimizar fragmentacion\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def detectar_yso_confundidas(preds, true, ids, label_encoder):\n",
    "    \"\"\"\n",
    "    Retorna un DataFrame con los objetos cuya clase fue predicha como YSO,\n",
    "    pero su clase real era diferente.\n",
    "    \"\"\"\n",
    "    inv_label_encoder = {v: k for k, v in label_encoder.items()}\n",
    "\n",
    "    errores = []\n",
    "    for pred, real, obj_id in zip(preds, true, ids):\n",
    "        clase_pred = inv_label_encoder[pred]\n",
    "        clase_real = inv_label_encoder[real]\n",
    "        if clase_pred == \"Young Stellar Object\" and clase_real != \"Young Stellar Object\":\n",
    "            errores.append({\"id_objeto\": obj_id, \"clase_real\": clase_real, \"clase_predicha\": clase_pred})\n",
    "\n",
    "    return pd.DataFrame(errores)\n",
    "\n",
    "\n",
    "# Cargar dataset y label encoder\n",
    "from src.fase2.script_1_transformer_preprocessing_optimizado_2 import LightCurveDataset\n",
    "#torch.serialization.add_safe_globals([LightCurveDataset])\n",
    "\n",
    "val_dataset = torch.load(\"../data/train/val_dataset.pt\", weights_only=False)\n",
    "\n",
    "# Verificacion rapida\n",
    "# Cargar un sample cualquiera\n",
    "sample = val_dataset[0]\n",
    "# Ver cu√°ntos elementos contiene\n",
    "print(\"N¬∫ de elementos devueltos por __getitem__:\", len(sample))\n",
    "# Inspeccionar los elementos\n",
    "for i, item in enumerate(sample):\n",
    "    print(f\"Elemento {i}: {type(item)}, shape o valor: {getattr(item, 'shape', item)}\")\n",
    "\n",
    "with open(\"../data/train/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "num_classes = len(label_encoder)\n",
    "class_names = list(label_encoder.keys())\n",
    "\n",
    "# Dataloader con batch peque√±o\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=6, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "# Crear el modelo con la arquitectura esperada\n",
    "args = argparse.Namespace(\n",
    "    input_dim=1,\n",
    "    in_channels=1,\n",
    "    encoder_dim=256,\n",
    "    hidden_dim=384,\n",
    "    output_dim=num_classes,\n",
    "    num_heads=8,\n",
    "    num_layers=8,\n",
    "    dropout=0.4, dropout_p=0.4,\n",
    "    stride=32,\n",
    "    kernel_size=3,\n",
    "    norm=\"postnorm\",\n",
    "    encoder=[\"mhsa_pro\", \"conv\", \"conv\"],\n",
    "    timeshift=False,\n",
    "    device=device\n",
    ")\n",
    "model = AstroConformerClassifier(args, num_classes=len(label_encoder), feature_dim=7)\n",
    "\n",
    "# Cargar los pesos entrenados\n",
    "state_dict = torch.load(\"../outputs/mejor_modelo_finetuned_optimizado2_features_segunda_vuelta.pt\", map_location=\"cpu\")\n",
    "# Elimina el prefijo \"_orig_mod.\" de las claves\n",
    "new_state_dict = {k.replace(\"_orig_mod.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "# Pasar a GPU si est√° disponible\n",
    "model = model.to(device)\n",
    "model.eval()  # Muy importante: modo evaluaci√≥n\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Evaluar con IDs\n",
    "val_loss, preds, true, ids = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "# Detectar YSO mal clasificadas\n",
    "df_yso_mal = detectar_yso_confundidas(preds, true, ids, label_encoder)\n",
    "df_yso_mal.to_csv(\"../outputs/yso_clase_predicha_error.csv\", index=False)\n",
    "\n",
    "print(f\"YSOs mal clasificadas detectadas: {len(df_yso_mal)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc3b4cb-ab6d-4473-9173-fc9b0b7198a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar CSV de todas las curvas (con clase real)\n",
    "df_all = pd.read_csv(\"../data/train/debug_clases_codificadas.csv\")\n",
    "\n",
    "# Cargar errores donde se predijo YSO y no lo era (CASO A)\n",
    "df_yso_fp = pd.read_csv(\"../outputs/yso_clase_predicha_error.csv\")\n",
    "ids_fp = set(df_yso_fp[\"id_objeto\"])\n",
    "\n",
    "# Cargar errores generales de clasificacion (CASO B)\n",
    "df_errores = pd.read_csv(\"outputs/errores_mal_clasificados_features_tercera_vuelta.csv\")\n",
    "\n",
    "# A√±adir ID si est√° disponible (debes tener otro CSV con √≠ndices ‚Üí IDs si no lo incluiste)\n",
    "# Aqu√≠ asumimos que ya tienes columna \"id_objeto\" cruzada\n",
    "df_fn_yso = df_errores[\n",
    "    df_errores[\"clase_real\"] == \"Young Stellar Object\"\n",
    "].copy()\n",
    "ids_fn = set(df_fn_yso[\"id_objeto\"])\n",
    "\n",
    "# üîÅ CURVAS QUE QUEREMOS DEPURAR = uni√≥n de ambas\n",
    "ids_dudosos = ids_fp.union(ids_fn)\n",
    "\n",
    "# Filtrar todas las YSO reales del dataset original\n",
    "df_yso_all = df_all[df_all[\"clase_variable_normalizada\"] == \"Young Stellar Object\"].copy()\n",
    "\n",
    "# Marcar cu√°les son dudosas\n",
    "df_yso_all[\"dudosa\"] = df_yso_all[\"id_objeto\"].isin(ids_dudosos)\n",
    "\n",
    "# Estad√≠sticas\n",
    "print(f\"üî¢ Total YSO reales: {len(df_yso_all)}\")\n",
    "print(f\"‚ö†Ô∏è YSO dudosas detectadas: {df_yso_all['dudosa'].sum()}\")\n",
    "\n",
    "# Ordenar para dejar las seguras primero\n",
    "df_yso_ordenadas = df_yso_all.sort_values(by=\"dudosa\", ascending=True)\n",
    "\n",
    "# Seleccionar 9000 curvas m√°s confiables\n",
    "df_yso_final = df_yso_ordenadas.head(9000).copy()\n",
    "\n",
    "# Guardar resultado\n",
    "df_yso_final.to_csv(\"outputs/ysos_9000_filtradas_seguras.csv\", index=False)\n",
    "print(\"‚úÖ Guardado en outputs/ysos_9000_filtradas_seguras.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
