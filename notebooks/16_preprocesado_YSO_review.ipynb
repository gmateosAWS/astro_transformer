{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155786fb",
   "metadata": {},
   "source": [
    "# 16. Preprocesado: revisi√≥n de la clase YSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0d3598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuraci√≥n de entorno aplicada.\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n general para evitar errores de warnings y compatibilidad\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"RICH_NO_RICH\"] = \"1\"\n",
    "print(\"Configuraci√≥n de entorno aplicada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6969fb91",
   "metadata": {},
   "source": [
    "## NUEVO PREPROCESADO GUARDANDO IDs DE OBJETOS\n",
    "\n",
    "Luego se pueden usar para filtrar curvas dudosas que no est√°n clasificando bien, y as√≠ depurar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac49593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Cargando datos en lotes con PyArrow...\n",
      "üíæ [INFO] Cargando agrupaci√≥n de curvas desde cache: /home/ec2-user/SageMaker/astro_transformer/src/fase2/../../data/train/grouped_data.pkl\n",
      "‚úÖ [INFO] Agrupaci√≥n cargada desde cache. Total objetos: 55439\n",
      "‚è≥ [INFO] Tiempo en agrupaci√≥n de datos: 10.9 segundos\n",
      "üöÄ Procesando 55439 curvas en paralelo usando 20 CPUs...\n",
      "‚è≥ [INFO] Tiempo en procesamiento paralelo: 82.2 segundos\n",
      "üîã [INFO] Curvas v√°lidas tras filtrado: 55342\n",
      "\n",
      "üîç Realizando prueba r√°pida en caracter√≠sticas auxiliares...\n",
      "‚úÖ Sample 0 sin problemas: [-0.54765874 -0.46691176 -0.58238172 -0.45465844 -0.48360653 -0.18917597\n",
      "  0.26550589]\n",
      "‚úÖ Sample 1 sin problemas: [-0.31123622 -0.23529412 -0.42088094 -0.30324447 -0.22950819  0.35237014\n",
      " -0.16461357]\n",
      "‚úÖ Sample 2 sin problemas: [-0.50290883 -0.43382352 -0.54812398 -0.73793606 -0.4426229  -0.35511186\n",
      " -0.06430592]\n",
      "‚úÖ Sample 3 sin problemas: [ 1.37089379  1.63602933  0.83931489 -1.24292777  1.21311469 -1.06736809\n",
      " -0.27657237]\n",
      "‚úÖ Sample 4 sin problemas: [-0.13150858  0.07536761 -0.32218598 -0.43718764  0.0942623   0.37391438\n",
      " -0.49674234]\n",
      "‚úÖ Sample 5 sin problemas: [-0.33489974 -0.30147059 -0.26835236 -1.38727051 -0.30327867  0.46031976\n",
      "  0.67637753]\n",
      "‚úÖ Sample 6 sin problemas: [ 0.78642899  0.94485279  0.51957583 -0.43427584  0.85245892 -1.17465803\n",
      " -0.05892404]\n",
      "‚úÖ Sample 7 sin problemas: [-0.54369489 -0.47058824 -0.58727572 -0.90474131 -0.48360653  0.40456442\n",
      "  0.02911986]\n",
      "‚úÖ Sample 8 sin problemas: [ 0.41094463  0.64705874  0.53344213  0.77953393  0.76229505  0.2181877\n",
      " -0.23647418]\n",
      "‚úÖ Sample 9 sin problemas: [ 0.80021573  1.13327205  0.21044047  0.14496675  0.77049179 -1.01843543\n",
      " -0.3953826 ]\n",
      "‚úÖ Prueba r√°pida completada.\n",
      "üìÅ Features median y IQR guardados en: /home/ec2-user/SageMaker/astro_transformer/src/fase2/../../data/train/features_stats.pkl\n",
      "[INFO] Uso de memoria de sequences: 10555.65 MB\n",
      "[INFO] Uso de memoria de masks: 10555.65 MB\n",
      "[INFO] Uso de memoria de features: 2.96 MB\n",
      "[INFO] Uso de memoria de labels: 0.21 MB\n",
      "[INFO] N curvas: 55342, seq_length: 25000\n",
      "[INFO] Estimaci√≥n memoria sequences (float16): 2.58 GB\n",
      "[INFO] Estimaci√≥n memoria sequences (float32): 5.15 GB\n",
      "[INFO] Si tienes problemas de memoria, considera usar almacenamiento en disco y Dataset bajo demanda.\n",
      "üíæ [INFO] Guardando label_encoder.pkl...\n",
      "üìä Recuento por clase codificada:\n",
      " 5 (Rotational): 9000\n",
      " 3 (Irregular): 9000\n",
      " 4 (RR Lyrae): 9000\n",
      " 2 (Eclipsing Binary): 9000\n",
      " 6 (Young Stellar Object): 9799\n",
      " 0 (Cataclysmic): 2080\n",
      " 1 (Delta Scuti): 7463\n",
      "üìù [INFO] Realizando split train/val/test...\n",
      "Train: 38739 | Val: 11068 | Test: 5535\n",
      "üìä [INFO] IDs de refuerzo incluidos en train: 0\n",
      "üíæ [INFO] Guardando datasets serializados en formato .pt...\n",
      "\n",
      "üìâ Resumen de curvas descartadas:\n",
      "üî∏ Ok                            : 55342\n",
      "üî∏ Short curve                   : 97\n",
      "‚úÖ Datos preparados como secuencias normalizadas y m√°scaras.\n",
      "‚è≥ [INFO] Tiempo total de ejecuci√≥n: 4.35 minutos (260.8 segundos)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f1cae76d5d0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1cae76e3b0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# A√±adir la ra√≠z del proyecto al path\n",
    "ROOT_DIR = Path.cwd().parent  # <- sube un nivel para alcanzar la ra√≠z del proyecto\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT_DIR))\n",
    "\n",
    "# Ignorar solo los RuntimeWarning de numpy (como overflows en reduce)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"numpy\")\n",
    "\n",
    "from src.fase2.script_1_transformer_preprocessing_optimizado_2 import main as preprocessing_optimized_with_features\n",
    "\n",
    "max_per_class_override={\n",
    "    \"Irregular\": 9000,\n",
    "    \"Rotational\": 9000,\n",
    "    \"Eclipsing Binary\": 9000,\n",
    "    \"Delta Scuti\": None,            # 7.550 ‚Üí TODAS\n",
    "    \"RR Lyrae\": 9000,               # 41.208 ‚Üí TODAS NO\n",
    "    \"Young Stellar Object\": None,   # 9.809 ‚Üí TODAS\n",
    "    \"Cataclysmic\": None,            # 2.080 ‚Üí TODAS\n",
    "    \"White Dwarf\": 0,               # 0 ‚Üí LA ELIMINAMOS\n",
    "    \"Variable\": 0                   # 0 ‚Üí LA ELIMINAMOS\n",
    "}\n",
    "\n",
    "preprocessing_optimized_with_features(\n",
    "    seq_length=25000,\n",
    "    max_per_class=None, # usamos override completo\n",
    "    max_per_class_override=max_per_class_override,\n",
    "    parquet_batch_size=10_000_000,\n",
    "    dataloader_batch_size=128,\n",
    "    num_workers=20,\n",
    "    #errores_csv_path=Path(\"../outputs/errores_mal_clasificados.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90c6f0",
   "metadata": {},
   "source": [
    "**Con el siguiente script intentamos detectar los IDs de las curvas YSO que est√°n confundiendo al modelo**.\n",
    "\n",
    "En la matriz de confusi√≥n vimos muchos casos de clase predicha YSO que en realidad era cualquiera de las otras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0109fee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N¬∫ de elementos devueltos por __getitem__: 5\n",
      "Elemento 0: <class 'torch.Tensor'>, shape o valor: torch.Size([25000])\n",
      "Elemento 1: <class 'torch.Tensor'>, shape o valor: torch.Size([])\n",
      "Elemento 2: <class 'torch.Tensor'>, shape o valor: torch.Size([25000])\n",
      "Elemento 3: <class 'torch.Tensor'>, shape o valor: torch.Size([7])\n",
      "Elemento 4: <class 'str'>, shape o valor: AP28318078\n",
      "YSOs mal clasificadas detectadas: 868\n",
      "Total de errores detectados: 2349\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.serialization\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# A√±adir la ra√≠z del proyecto al path\n",
    "ROOT_DIR = Path.cwd().parent  # <- sube un nivel para alcanzar la ra√≠z del proyecto\n",
    "if str(ROOT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT_DIR))\n",
    "\n",
    "# Ignorar solo los RuntimeWarning de numpy (como overflows en reduce)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"numpy\")\n",
    "\n",
    "from src.fase2.script_2_transformer_fine_tuning_optimizado import AstroConformerClassifier as AstroConformerClassifier, evaluate\n",
    "\n",
    "# Detectar dispositivo\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# acciones para resolver los problemas de memoria\n",
    "# 1. Liberar memoria\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 2. Optimizar fragmentacion\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def detectar_yso_confundidas(preds, true, ids, class_names):\n",
    "    errores = []\n",
    "    for pred, real, obj_id in zip(preds, true, ids):\n",
    "        clase_pred = class_names[pred]\n",
    "        clase_real = class_names[real]\n",
    "        if clase_pred == \"Young Stellar Object\" and clase_real != \"Young Stellar Object\":\n",
    "            errores.append({\n",
    "                \"id_objeto\": obj_id,\n",
    "                \"clase_real\": clase_real,\n",
    "                \"clase_predicha\": clase_pred\n",
    "            })\n",
    "    return pd.DataFrame(errores)\n",
    "\n",
    "def detectar_todos_los_errores(preds, true, ids, class_names):\n",
    "    errores = []\n",
    "    for pred, real, obj_id in zip(preds, true, ids):\n",
    "        clase_pred = class_names[pred]\n",
    "        clase_real = class_names[real]\n",
    "        if clase_pred != clase_real:\n",
    "            errores.append({\n",
    "                \"id_objeto\": obj_id,\n",
    "                \"clase_real\": clase_real,\n",
    "                \"clase_predicha\": clase_pred\n",
    "            })\n",
    "    return pd.DataFrame(errores)\n",
    "\n",
    "\n",
    "# Cargar dataset y label encoder\n",
    "from src.fase2.script_1_transformer_preprocessing_optimizado_2 import LightCurveDataset\n",
    "#torch.serialization.add_safe_globals([LightCurveDataset])\n",
    "\n",
    "val_dataset = torch.load(\"../data/train/val_dataset.pt\", weights_only=False)\n",
    "\n",
    "# Verificacion rapida\n",
    "# Cargar un sample cualquiera\n",
    "sample = val_dataset[0]\n",
    "# Ver cu√°ntos elementos contiene\n",
    "print(\"N¬∫ de elementos devueltos por __getitem__:\", len(sample))\n",
    "# Inspeccionar los elementos\n",
    "for i, item in enumerate(sample):\n",
    "    print(f\"Elemento {i}: {type(item)}, shape o valor: {getattr(item, 'shape', item)}\")\n",
    "\n",
    "with open(\"../data/train/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "num_classes = len(label_encoder)\n",
    "class_names = list(label_encoder.keys())\n",
    "\n",
    "# Imprimir contenido del label encoder\n",
    "print(\"Contenido del label encoder:\")\n",
    "for key, value in label_encoder.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Dataloader con batch peque√±o\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=6, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "# Crear el modelo con la arquitectura esperada\n",
    "args = argparse.Namespace(\n",
    "    input_dim=1,\n",
    "    in_channels=1,\n",
    "    encoder_dim=256,\n",
    "    hidden_dim=384,\n",
    "    output_dim=num_classes,\n",
    "    num_heads=8,\n",
    "    num_layers=8,\n",
    "    dropout=0.4, dropout_p=0.4,\n",
    "    stride=32,\n",
    "    kernel_size=3,\n",
    "    norm=\"postnorm\",\n",
    "    encoder=[\"mhsa_pro\", \"conv\", \"conv\"],\n",
    "    timeshift=False,\n",
    "    device=device\n",
    ")\n",
    "model = AstroConformerClassifier(args, num_classes=len(label_encoder), feature_dim=7)\n",
    "\n",
    "# Cargar los pesos entrenados\n",
    "state_dict = torch.load(\"../outputs/mejor_modelo_finetuned_optimizado2_features_segunda_vuelta.pt\", map_location=\"cpu\")\n",
    "# Elimina el prefijo \"_orig_mod.\" de las claves\n",
    "new_state_dict = {k.replace(\"_orig_mod.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "# Pasar a GPU si est√° disponible\n",
    "model = model.to(device)\n",
    "model.eval()  # Muy importante: modo evaluaci√≥n\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Evaluar con IDs\n",
    "val_loss, preds, true, ids = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "# Detectar YSO mal clasificadas\n",
    "df_yso_mal = detectar_yso_confundidas(preds, true, ids, class_names)\n",
    "df_yso_mal.to_csv(\"../outputs/yso_clase_predicha_error.csv\", index=False)\n",
    "# Detectar todos los errores\n",
    "df_todos_errores = detectar_todos_los_errores(preds, true, ids, class_names)\n",
    "df_todos_errores.to_csv(\"../outputs/todos_los_errores.csv\", index=False)\n",
    "\n",
    "print(f\"YSOs mal clasificadas detectadas: {len(df_yso_mal)}\")\n",
    "print(f\"Total de errores detectados: {len(df_todos_errores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cc3b4cb-ab6d-4473-9173-fc9b0b7198a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Total de IDs falsos positivos (YSO predicha pero no real): 868\n",
      "üîç Ejemplos de IDs falsos positivos (YSO predicha pero no real):\n",
      "ID 1: ASASSN-V J025637.39+260456.2\n",
      "ID 2: ZTFJ032204.91+445907.8\n",
      "ID 3: TIC_346741139.0\n",
      "ID 4: ASASSN-V J040855.11-421656.9\n",
      "ID 5: ASASSN-V J232708.21+371216.7\n",
      "üîç Total de IDs falsos negativos (YSO real pero no predicha): 419\n",
      "üîç Ejemplos de IDs falsos negativos (YSO real pero no predicha):\n",
      "ID 1: ZTFJ031546.61+753355.3\n",
      "ID 2: ASASSN-V J060134.99+420407.5\n",
      "ID 3: ASASSN-V J030959.52-145243.3\n",
      "ID 4: ZTFJ000938.42+535310.9\n",
      "ID 5: ASASSN-V J110149.94-101744.5\n",
      "üîç Ejemplos de IDs dudosos:\n",
      "ID 1: ZTFJ032204.91+445907.8\n",
      "ID 2: ASASSN-V J034309.74+104654.3\n",
      "ID 3: ASASSN-V J004220.88+494920.1\n",
      "ID 4: ASASSN-V J060430.43-411308.8\n",
      "ID 5: ASASSN-V J014956.41+275529.0\n",
      "üî¢ Total YSO reales: 9799\n",
      "‚ö†Ô∏è YSO dudosas detectadas: 230\n",
      "‚úÖ Guardado en outputs/ysos_9000_filtradas_seguras.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar CSV de todas las curvas (con clase real)\n",
    "df_all = pd.read_csv(\"../data/train/debug_clases_codificadas.csv\")\n",
    "\n",
    "# Cargar errores donde se predijo YSO y no lo era (CASO A)\n",
    "df_yso_fp = pd.read_csv(\"../outputs/yso_clase_predicha_error.csv\")\n",
    "ids_fp = set(df_yso_fp[\"id_objeto\"])\n",
    "\n",
    "# Imprimir algunos ejemplos de IDs falsos positivos y el total\n",
    "print(f\"üîç Total de IDs falsos positivos (YSO predicha pero no real): {len(ids_fp)}\")\n",
    "print(\"üîç Ejemplos de IDs falsos positivos (YSO predicha pero no real):\")\n",
    "for i, obj_id in enumerate(ids_fp):\n",
    "    if i < 5:  # Limitar a 5 ejemplos\n",
    "        print(f\"ID {i+1}: {obj_id}\")\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Cargar errores generales de clasificacion (CASO B)\n",
    "df_errores = pd.read_csv(\"../outputs/todos_los_errores.csv\")\n",
    "\n",
    "# A√±adir ID si est√° disponible (debes tener otro CSV con √≠ndices ‚Üí IDs si no lo incluiste)\n",
    "# Aqu√≠ asumimos que ya tienes columna \"id_objeto\" cruzada\n",
    "df_fn_yso = df_errores[\n",
    "    df_errores[\"clase_real\"] == \"Young Stellar Object\"\n",
    "].copy()\n",
    "ids_fn = set(df_fn_yso[\"id_objeto\"])\n",
    "\n",
    "# Imprimir algunos ejemplos de IDs falsos negativos y el total\n",
    "print(f\"üîç Total de IDs falsos negativos (YSO real pero no predicha): {len(ids_fn)}\")\n",
    "print(\"üîç Ejemplos de IDs falsos negativos (YSO real pero no predicha):\")\n",
    "for i, obj_id in enumerate(ids_fn):\n",
    "    if i < 5:  # Limitar a 5 ejemplos\n",
    "        print(f\"ID {i+1}: {obj_id}\")\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# üîÅ CURVAS QUE QUEREMOS DEPURAR = uni√≥n de ambas\n",
    "ids_dudosos = ids_fp.union(ids_fn)\n",
    "\n",
    "# Imrpimir algunos ejemplos de IDs dudosos\n",
    "print(\"üîç Ejemplos de IDs dudosos:\" )\n",
    "for i, obj_id in enumerate(ids_dudosos):\n",
    "    if i < 5:  # Limitar a 5 ejemplos\n",
    "        print(f\"ID {i+1}: {obj_id}\")\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Filtrar todas las YSO reales del dataset original\n",
    "df_yso_all = df_all[df_all[\"clase_variable\"] == \"Young Stellar Object\"].copy()\n",
    "\n",
    "# Marcar cu√°les son dudosas\n",
    "df_yso_all[\"dudosa\"] = df_yso_all[\"id\"].isin(ids_dudosos)\n",
    "\n",
    "# Estad√≠sticas\n",
    "print(f\"üî¢ Total YSO reales: {len(df_yso_all)}\")\n",
    "print(f\"‚ö†Ô∏è YSO dudosas detectadas: {df_yso_all['dudosa'].sum()}\")\n",
    "\n",
    "# Ordenar para dejar las seguras primero\n",
    "df_yso_ordenadas = df_yso_all.sort_values(by=\"dudosa\", ascending=True)\n",
    "\n",
    "# Seleccionar 9000 curvas m√°s confiables\n",
    "df_yso_final = df_yso_ordenadas.head(9000).copy()\n",
    "\n",
    "# Guardar resultado\n",
    "df_yso_final.to_csv(\"../data/train/ysos_9000_filtradas_seguras.csv\", index=False)\n",
    "print(\"‚úÖ Guardado en outputs/ysos_9000_filtradas_seguras.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b88a96d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Total de FALSOS NEGATIVOS (YSO reales pero no predichas): 419\n",
      "üîç Total de FALSOS POSITIVOS (YSO predichas pero no reales): 868\n",
      "üîç Total de curvas a eliminar: 1287\n",
      "motivo_descarte\n",
      "YSO predicha incorrectamente (FP)    868\n",
      "YSO mal clasificada (FN)             419\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä Desglose por clase original (impacto en dataset):\n",
      "clase_original\n",
      "Young Stellar Object    419\n",
      "Eclipsing Binary        237\n",
      "Cataclysmic             193\n",
      "Rotational              187\n",
      "RR Lyrae                112\n",
      "Delta Scuti              80\n",
      "Irregular                59\n",
      "Name: count, dtype: int64\n",
      "‚úÖ Guardado en: ../data/train/curvas_a_eliminar_por_confusion_yso.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Cargar CSV de todas las curvas con su clase real\n",
    "df_all = pd.read_csv(\"../data/train/debug_clases_codificadas.csv\")\n",
    "\n",
    "# 2. FALSOS NEGATIVOS: eran YSO pero el modelo no las predijo como tal\n",
    "df_errores = pd.read_csv(\"../outputs/todos_los_errores.csv\")\n",
    "df_fn = df_errores[df_errores[\"clase_real\"] == \"Young Stellar Object\"].copy()\n",
    "df_fn[\"motivo_descarte\"] = \"YSO mal clasificada (FN)\"\n",
    "df_fn = df_fn[[\"id_objeto\", \"clase_real\", \"motivo_descarte\"]]\n",
    "df_fn.rename(columns={\"clase_real\": \"clase_original\"}, inplace=True)\n",
    "# Imprimir total de FN\n",
    "print(f\"üîç Total de FALSOS NEGATIVOS (YSO reales pero no predichas): {len(df_fn)}\")\n",
    "\n",
    "# 3. FALSOS POSITIVOS: no eran YSO pero el modelo las predijo como YSO\n",
    "df_fp = pd.read_csv(\"../outputs/yso_clase_predicha_error.csv\")\n",
    "df_fp[\"motivo_descarte\"] = \"YSO predicha incorrectamente (FP)\"\n",
    "df_fp.rename(columns={\"clase_real\": \"clase_original\", \"id\": \"id_objeto\"}, inplace=True)\n",
    "df_fp = df_fp[[\"id_objeto\", \"clase_original\", \"motivo_descarte\"]]\n",
    "# Imprimir total de FP\n",
    "print(f\"üîç Total de FALSOS POSITIVOS (YSO predichas pero no reales): {len(df_fp)}\")\n",
    "\n",
    "# 4. Unir ambos\n",
    "df_dudosos = pd.concat([df_fn, df_fp], ignore_index=True)\n",
    "\n",
    "# 5. Verificar qu√© porcentaje representan\n",
    "print(f\"üîç Total de curvas a eliminar: {len(df_dudosos)}\")\n",
    "print(df_dudosos[\"motivo_descarte\"].value_counts())\n",
    "\n",
    "# 6. A√±adir columna auxiliar para posibles an√°lisis\n",
    "df_dudosos[\"origen\"] = df_dudosos[\"id_objeto\"].apply(\n",
    "    lambda x: \"ASASSN\" if \"ASASSN\" in x else \"ZTF\" if \"ZTF\" in x else \"TESS\" if \"TIC_\" in x else \"Otros\"\n",
    ")\n",
    "\n",
    "# 7. Generar desglose por clase real\n",
    "print(\"\\nüìä Desglose por clase original (impacto en dataset):\")\n",
    "print(df_dudosos[\"clase_original\"].value_counts())\n",
    "\n",
    "# 8. Guardar CSV de curvas a eliminar\n",
    "df_dudosos.to_csv(\"../data/train/curvas_a_eliminar_por_confusion_yso.csv\", index=False)\n",
    "print(\"‚úÖ Guardado en: ../data/train/curvas_a_eliminar_por_confusion_yso.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
