{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c321f5d",
   "metadata": {},
   "source": [
    "# Descarga y consolidaci√≥n de curvas Kepler y TESS (Script 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a96814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n general para evitar errores de warnings y compatibilidad\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"RICH_NO_RICH\"] = \"1\"\n",
    "print(\"Configuraci√≥n de entorno aplicada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0624e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install missing packages\n",
    "%pip install torch lightkurve\n",
    "%pip install -q pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac74e2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, lightkurve as lk\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Lightkurve:\", lk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad96adb",
   "metadata": {},
   "source": [
    "### üì• Script 1: descarga y consolidaci√≥n de curvas de Kepler y TESS de la clase EB (entorno local o SageMaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a9c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code from script_1_kepler_tess_eb...\n",
    "import warnings\n",
    "import os, sys, platform\n",
    "import glob\n",
    "from astropy.units import UnitsWarning\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UnitsWarning)\n",
    "print(\"üîá Warnings silenciados: UserWarning, FutureWarning\")\n",
    "os.environ[\"RICH_NO_RICH\"] = \"1\"\n",
    "\n",
    "src_path = Path(\"src\").resolve()\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "from src.fase1.script_1_kepler_tess_eb import main as run_script_1\n",
    "\n",
    "try:\n",
    "    import sagemaker\n",
    "    is_sagemaker = True\n",
    "except ImportError:\n",
    "    is_sagemaker = False\n",
    "\n",
    "existing = len(glob.glob(\"/home/ec2-user/backup/data/raw/kepler/*.csv\")) + len(glob.glob(\"/home/ec2-user/backup/data/raw/tess/*.csv\"))\n",
    "print(f\"üóÉÔ∏è Curvas ya existentes en disco: {existing}\", flush=True)\n",
    "\n",
    "if is_sagemaker:\n",
    "    print(\"üîÅ Ejecutando en SageMaker ‚Üí cat√°logo completo\")\n",
    "    run_script_1(mission=\"Kepler\", only_pending=True)\n",
    "else:\n",
    "    print(\"üíª Ejecutando en entorno local ‚Üí cat√°logo de prueba\")\n",
    "    run_script_1(use_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a5a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.cleanup_raw import cleanup_raw_data\n",
    "\n",
    "# Limpiar los datos de prueba\n",
    "#cleanup_raw_data('/home/ec2-user/backup/data/raw', confirm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4347edde",
   "metadata": {},
   "source": [
    "##### üì• Comprobaci√≥n de los fichero de curvas Kepler y TESS (EB) mergeado y consolidado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94cfd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "\n",
    "for name in [\"kepler\", \"tess\"]:\n",
    "    path = Path(f\"data/processed/dataset_eb_{name}_labeled.parquet\")\n",
    "    if not path.exists():\n",
    "        print(f\"‚ùå Archivo no encontrado: {path}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        parquet_file = pq.ParquetFile(path)\n",
    "        schema = parquet_file.schema_arrow\n",
    "        columns = schema.names\n",
    "\n",
    "        print(f\"\\nüì¶ {name.upper()} contiene {len(columns)} columnas:\")\n",
    "        print(columns)\n",
    "\n",
    "        if \"clase_variable\" in columns:\n",
    "            print(f\"‚úÖ 'clase_variable' est√° presente en {name.upper()}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  'clase_variable' NO est√° presente en {name.upper()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error leyendo {path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d3dbc3",
   "metadata": {},
   "source": [
    "### ‚úÖ FIX de la columna \"clase_variable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d8be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "\n",
    "def reparar_parquet_streaming(parquet_path: Path, output_path: Path, clase_default: str = \"EB\"):\n",
    "    dataset = ds.dataset(parquet_path, format=\"parquet\")\n",
    "    sample_batch = next(dataset.to_batches(batch_size=100))\n",
    "    schema_original = sample_batch.schema\n",
    "    schema_nueva = schema_original.append(pa.field(\"clase_variable\", pa.string()))\n",
    "    writer = pq.ParquetWriter(output_path, schema=schema_nueva, compression=\"snappy\")\n",
    "    print(f\"[üîß] Reparando parquet: {parquet_path.name}\")\n",
    "    fragmentos = dataset.to_batches(batch_size=50000)\n",
    "    for batch in tqdm(fragmentos, desc=\"üõ†Ô∏è Reparando por lotes\"):\n",
    "        n = batch.num_rows\n",
    "        columna_clase = pa.array([clase_default] * n, type=pa.string())\n",
    "        batch_corregido = batch.append_column(\"clase_variable\", columna_clase)\n",
    "        writer.write_table(pa.Table.from_batches([batch_corregido], schema=schema_nueva))\n",
    "    writer.close()\n",
    "    print(f\"[‚úÖ] Reparaci√≥n completada ‚Üí {output_path}\")\n",
    "\n",
    "# Ejemplo de uso:\n",
    "reparar_parquet_streaming(Path(\"data/processed/dataset_eb_tess.parquet\"),\n",
    "                          Path(\"data/processed/dataset_eb_tess_labeled.parquet\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
